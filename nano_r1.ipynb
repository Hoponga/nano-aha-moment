{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nanoAhaMoment: Single File \"RL for LLM\" Library\n",
    "Single GPU · No TRL or Verl · Efficient · 3B Base Model · Full Parameter Tuning Implementation of R1-zero training.\n",
    "\n",
    "Inspired by [TinyZero](https://github.com/Jiayi-Pan/TinyZero) and [Mini-R1](https://www.philschmid.de/mini-deepseek-r1), but designed to be **simpler**, **cleaner**, and **faster**, with every line of code visible and understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R1-Zero is arguably the more interesting contribution from the DeepSeek R1 paper. The core idea: take a freshly pre-trained LLM (straight out of the unsupervised pretraining oven) and continue its training using reinforcement learning *without* any human feedback or supervision. The result? A model that starts showing emergent behaviors like self-reflection, verification, backtracking that researchers have tried to bake into LLMs using handcrafted tricks and inductive biases, at least since O1.\n",
    "\n",
    "In this notebook, we’ll build an R1-Zero-style training loop **from scratch**. The goal is to create a crystal-clear, hackable foundation for RL-style LLM training; one that gives you a bird’s-eye view of every moving part and how they fit together. Perfect for playing around, extending, or hacking.\n",
    "\n",
    "---\n",
    "\n",
    "### Why another R1-Zero implementation?\n",
    "\n",
    "There are already great implementations like [TinyZero](https://github.com/Jiayi-Pan/TinyZero) and [Mini-R1](https://www.philschmid.de/mini-deepseek-r1). But they rely on full-fledged RL libraries (like `trl` or `verl`) to handle training.\n",
    "\n",
    "These libraries exist for good reason; efficient RL training for LLMs sits at the crossroads of scalable training and fast inference. Making that work takes a lot of engineering. But that also means the internals are often abstracted away, hard to read, and even harder to tweak.\n",
    "\n",
    "This notebook is different: **no abstractions, no hiding**. You’ll see everything, top to bottom. A lightweight, readable codebase that still follows best practices and runs efficiently on a single GPU.\n",
    "\n",
    "### What is this notebook, exactly?\n",
    "\n",
    "We'll train a base LLM using RL to solve a reasoning-heavy algorithmic task. The setup:\n",
    "\n",
    "- **Model**: Qwen2.5 3B-Base  \n",
    "- **Dataset**: Countdown-Tasks-3to4  \n",
    "- **Algorithm**: GRPO (a variant of policy gradient)\n",
    "\n",
    "Yes, the task is a bit toy-ish—but it captures the essence of R1-Zero: emergent behaviors like self-reflection, verification, backtracking, even language-switching. This setup is ideal for rapid prototyping and experimentation.\n",
    "\n",
    "### Who is this notebook for?\n",
    "\n",
    "- Anyone interested in RL training for LLMs  \n",
    "- Researchers, especially the ones in academia, exploring reasoning in language models\n",
    "\n",
    "### What should I know before jumping in?\n",
    "\n",
    "- A working knowledge of the HuggingFace Transformers library  \n",
    "- Some experience fine-tuning LLMs  \n",
    "- Familiarity with policy gradient methods (helpful but not required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R1-Zero Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to train a base LLM to **reason** in a way that allows it to **reevaluate** its own outputs and **improve** them, all without human supervision. The DeepSeek R1 paper proposes a surprisingly simple recipe to achieve this, and that's exactly what we'll implement in this notebook.\n",
    "\n",
    "### The Recipe\n",
    "\n",
    "Here's the high-level procedure:\n",
    "\n",
    "1. **Start** with a base LLM and a dataset containing problem prompts paired only with their *final answers* (no intermediate reasoning steps).  \n",
    "2. For each iteration $i = 0$ to `NUM_ITERATIONS`:\n",
    "   - Sample a batch of prompts $\\{x_i\\}_{i=1}^N$ from the dataset.\n",
    "   - For each prompt, sample $G$ responses from the model:  \n",
    "     $ y_1, y_2, \\cdots, y_G \\sim \\pi_\\theta(y|x) $\n",
    "\n",
    "     These $G$ responses form what is called a *group* in GRPO.\n",
    "   - Compute a reward $R_i$ for each response and normalize them tocalculate the GRPO advantage within each group.\n",
    "   - Create a list of $N \\times G$ episodes, i.e., pairs of $(x_i, y_i)$ along with their corresponding advantages.\n",
    "   - Estimate the policy gradient $\\vec{g}_{pg}$ from these episodes.\n",
    "   - Update the model parameters:  \n",
    "     $\\theta \\leftarrow \\theta + \\eta \\vec{g}_{pg}$\n",
    "\n",
    "### Code Structure Overview\n",
    "\n",
    "The code you will see is structured directly following this recipe. It boils down to three main components:\n",
    "\n",
    "1. **Episode Generation**  \n",
    "   - Generate $ (x, y) $ pairs along with their advantages for each RL iteration.\n",
    "   \n",
    "2. **Reward Calculation**  \n",
    "   - Compute rewards for each generated response.\n",
    "   \n",
    "3. **Policy Gradient Estimation**  \n",
    "   - Use the generated episodes to estimate the policy gradient and perform the model update.\n",
    "\n",
    "In the end, these three components come together in a simple loop that trains the model, step by step, to develop reasoning capabilities through reinforcement learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `notebooks/checkpoint_playground.ipynb`, you can load the model we already trained with this notebook and interactively test the model's reasoning capabilities. This notebook allows you to input custom prompts and observe the model's responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies\n",
    "\n",
    "Before we begin, let's install the necessary Python packages. We'll be using:\n",
    "\n",
    "- PyTorch  \n",
    "- Hugging Face Transformers  \n",
    "- Hugging Face Datasets  \n",
    "- DeepSpeed  \n",
    "- vLLM\n",
    "\n",
    "For a detailed, step-by-step installation guide, refer to the [README](https://github.com/McGill-NLP/tiny-aha-moment.git) of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the environment variables for HuggingFace\n",
    "# This is done to ensure that the cache directory for HuggingFace is set to a specific location,\n",
    "# preventing the storage from being overwhelmed with model files and other data.\n",
    "SCRATCH = \"/usr0/home/kailash/scratch\"\n",
    "os.environ[\"HF_HOME\"] = str(SCRATCH + \"/hf_home\")\n",
    "SCRATCH = Path(SCRATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3,4,5\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3,4,5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kailash/miniconda3/envs/vllm/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/kailash/miniconda3/envs/vllm/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/kailash/miniconda3/envs/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-04 01:10:07 [cuda.py:608] Detected different devices in the system: NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:10:09,598\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import time\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import deepspeed\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from deepspeed import DeepSpeedEngine\n",
    "from tqdm import trange\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "import wandb\n",
    "from utils import (\n",
    "    compute_token_log_probs,\n",
    "    dump_episodes,\n",
    "    evaluate_on_test_set,\n",
    "    find_free_port,\n",
    "    find_last_checkpoint,\n",
    "    prepare_model_inputs,\n",
    "    load_model_into_vllm\n",
    ")\n",
    "\n",
    "# Needed to stop DeepSpeed from complaining\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" \n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = str(find_free_port())\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We do have a few helper functions in `utils.py` that are used to keep the code clean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the hyperparameters for the training. These are mostly taken from [Mini-R1](https://www.philschmid.de/mini-deepseek-r1) implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs and Checkpoints will be saved to: /usr0/home/kailash/scratch/deepseek_r1z_hackathon/r1-zero\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-3B\"\n",
    "MODEL_CHAT_NAME = MODEL_NAME + \"-Instruct\"\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"Jiayi-Pan/Countdown-Tasks-3to4\"\n",
    "\n",
    "# Total number of training iterations\n",
    "NUM_ITERATIONS = 1000\n",
    "# Number of episodes to collect per iteration for training\n",
    "EPISODES_PER_ITERATION = 64\n",
    "# Number of responses to generate for each input prompt (i.e. group size in GRPO)\n",
    "GENERATIONS_PER_SAMPLE = 4\n",
    "# Controls how much the policy can deviate from the reference model\n",
    "KL_COEFFICIENT = 0.001\n",
    "\n",
    "# Training hyperparameters\n",
    "# Batch size for each GPU device during training\n",
    "PER_DEVICE_BATCH_SIZE = 4\n",
    "# Learning rate for model updates\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "# Sampling parameters\n",
    "# Maximum number of tokens to generate in each response\n",
    "MAX_RESPONSE_TOKENS = 1024\n",
    "# Controls randomness in generation (higher = more random)\n",
    "TEMPERATURE = 1.0\n",
    "# Nucleus sampling parameter (1.0 = disabled)\n",
    "TOP_P = 1.0\n",
    "# Top-k sampling parameter (-1 = disabled)\n",
    "TOP_K = -1  # no top k\n",
    "\n",
    "# DeepSpeed configuration\n",
    "# DeepSpeed config for the policy model\n",
    "deepspeed_config = {\n",
    "    \"bf16\": {\"enabled\": True},\n",
    "    \"zero_optimization\": {\"stage\": 2, \"overlap_comm\": False},\n",
    "    \"train_batch_size\": EPISODES_PER_ITERATION,\n",
    "    \"train_micro_batch_size_per_gpu\": PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_accumulation_steps\": EPISODES_PER_ITERATION // PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": LEARNING_RATE,\n",
    "            \"betas\": (0.9, 0.999),\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"torch_adam\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "# DeepSpeed config for the reference model\n",
    "ref_deepspeed_config = {\n",
    "    \"bf16\": {\"enabled\": True},\n",
    "    # Note that we don't train the reference model\n",
    "    # These are just for compatibility with DeepSpeed.\n",
    "    \"train_batch_size\": EPISODES_PER_ITERATION,\n",
    "    \"train_micro_batch_size_per_gpu\": PER_DEVICE_BATCH_SIZE,\n",
    "    \"gradient_accumulation_steps\": EPISODES_PER_ITERATION // PER_DEVICE_BATCH_SIZE,\n",
    "}\n",
    "\n",
    "RUN_NAME = \"r1-zero\"\n",
    "EXP_DIR = SCRATCH / \"deepseek_r1z_hackathon\" / RUN_NAME\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Logs and Checkpoints will be saved to: {EXP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the training prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we'll use the [Countdown-Tasks-3to4](https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4) dataset, which provides problem statements paired with their final answers (but no reasoning steps).\n",
    "\n",
    "### The Countdown Task\n",
    "\n",
    "The Countdown game is a numerical puzzle where the player must reach a target number using a set of randomly chosen numbers and basic arithmetic operations: addition, subtraction, multiplication, and division. Each number must be used exactly once.\n",
    "\n",
    "Example:\n",
    "\n",
    "```yaml\n",
    "Target: 622\n",
    "Available Numbers: [25, 3, 6, 100]\n",
    "\n",
    "# Not provided in the dataset\n",
    "Solution: (100 × 6) + (25 − 3) = 622\n",
    "```\n",
    "\n",
    "This task is ideal for training LLMs to practice reasoning, searching, and self-verification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using the base version of the model, which has only been pretrained on raw internet data, it has no prior understanding of system prompts or chat formatting. However, we will still use the chat format to make the resulting model compatible with downstream tools and frameworks that expect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a helpful assistant. You first think about the reasoning process in the mind \"\n",
    "    \"and then provide the user with the answer.\"\n",
    ")\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"Using the numbers {numbers}, create an equation that equals {target}. \"\n",
    "    \"You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. \"\n",
    "    \"Show your work in <think> </think> tags. And return the final equation and answer in \"\n",
    "    \"<answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the system message and prompt template, we can generate the training prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489864, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process dataset\n",
    "def preprocess_example(example: Dict[str, Any]):\n",
    "    numbers: List[int] = example[\"nums\"]\n",
    "    target: int = example[\"target\"]\n",
    "\n",
    "    prefix = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(numbers=numbers, target=target)},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let me solve this step by step.\\n<think>\"},\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        prefix, tokenize=True, continue_final_message=True\n",
    "    )\n",
    "    prompt = tokenizer.decode(\n",
    "        input_ids, skip_special_tokens=False, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return {\"prompt\": prompt, \"input_ids\": input_ids}\n",
    "\n",
    "# Note that the base model and \"instruct\" model have different eos token. \n",
    "# Here we make sure to use the correct one.\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHAT_NAME)\n",
    "EOS_TOKEN_ID = AutoTokenizer.from_pretrained(MODEL_NAME).eos_token_id\n",
    "EOS_TOKEN = tokenizer.convert_ids_to_tokens(EOS_TOKEN_ID)\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "dataset = dataset.map(preprocess_example, num_proc=6)\n",
    "\n",
    "# Split dataset\n",
    "train_test_split = dataset.train_test_split(test_size=500, seed=42)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  43\n",
      "Available Numbers:  [4, 27, 12]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target: \", train_dataset[0][\"target\"])\n",
    "print(\"Available Numbers: \", train_dataset[0][\"nums\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the system message and prompt template, we generate the following prompt for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [4, 27, 12], create an equation that equals 43. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you noticed, we also prepend the `<assistant>` tag along with the phrase *\"Let me solve this step by step.\"* to each prompt. This helps guide the model into **answering mode**. Without this, the base model might simply continue the prompt rather than attempting to solve the task, since it has no inherent understanding of instruction-following.\n",
    "\n",
    "Additionally, we tokenize each prompt and store the result as `input_ids`, which will be used later during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 1446, 1156, 1744, 911, 279, 32711, 1882, 304, 279, 3971, 323, 1221, 3410, 279, 1196, 448, 279, 4226, 13, 151645, 198, 151644, 872, 198, 16429, 279, 5109, 508, 19, 11, 220, 17, 22, 11, 220, 16, 17, 1125, 1855, 458, 23606, 429, 16819, 220, 19, 18, 13, 1446, 646, 990, 6770, 34784, 7525, 17973, 11, 85922, 11777, 608, 8, 323, 1817, 1372, 646, 1172, 387, 1483, 3055, 13, 6928, 697, 975, 304, 366, 26865, 29, 690, 26865, 29, 9492, 13, 1597, 470, 279, 1590, 23606, 323, 4226, 304, 366, 9217, 29, 690, 9217, 29, 9492, 11, 369, 3110, 366, 9217, 2235, 16, 488, 220, 17, 8, 608, 320, 18, 353, 220, 20, 12533, 9217, 14276, 151645, 198, 151644, 77091, 198, 10061, 752, 11625, 419, 3019, 553, 3019, 624, 13708, 766, 29]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepSeek R1 paper introduced **rule-based rewards** to evaluate whether the model-generated solutions were correct. We'll adopt a similar approach by defining two custom reward functions:\n",
    "\n",
    "- **Format Reward**: Checks if the output follows the required format:  \n",
    "  `<think> [thinking] </think><answer> [answer] </answer>`\n",
    "\n",
    "- **Equation Reward**: Extracts the equation from within the `<answer>` tag, verifies that it evaluates to the target result, and ensures that all available numbers are used exactly once.\n",
    "\n",
    "The purpose of enforcing the format is mainly to make answer extraction easier. It isn't strictly necessary for the correctness of the answer itself but simplifies parsing during training.\n",
    "\n",
    "The final reward assigned to an episode/trajectory (prompt+response) is simply the sum of these two components. Importantly, the reward is only computed at the **last token** of the output. From an RL perspective, this means that all intermediate actions receive zero reward. We also do not apply any discounting here (i.e., $\\gamma = 1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward_func(completion: str) -> float:\n",
    "    \"\"\"\n",
    "    Format: <think>...</think>\\n</answer>...</answer>\n",
    "\n",
    "    Also checks that the content within <answer>...</answer> conforms to a\n",
    "    specified pattern (only digits, + - * / ( ) . and whitespace).\n",
    "\n",
    "    Args:\n",
    "        completion (str): Generated output\n",
    "\n",
    "    Returns:\n",
    "        float: Reward score\n",
    "    \"\"\"\n",
    "    # Define the allowed pattern (only numbers, +, -, *, /, (, ), ., and whitespace)\n",
    "    allowed_pattern = r\"^[\\d+\\-*/().\\s]+$\"\n",
    "\n",
    "    try:\n",
    "        # add synthetic <think> as its already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Strip EOS token if present\n",
    "        if completion.endswith(EOS_TOKEN):\n",
    "            completion = completion[:-len(EOS_TOKEN)]\n",
    "\n",
    "        # Check if the format is correct\n",
    "        # Pattern means:\n",
    "        # 1) <think>...contents not including other <think> tags...</think>\n",
    "        # 2) \\n\n",
    "        # 3) <answer>...anything...</answer>\n",
    "        regex = r\"^<think>([^<]*(?:<(?!/?think>)[^<]*)*)<\\/think>\\n<answer>([\\s\\S]*?)<\\/answer>$\"\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "\n",
    "        if match is None or len(match.groups()) != 2:\n",
    "            # Format is incorrect\n",
    "            return 0.0\n",
    "        else:\n",
    "            # Extract the content inside <answer>...</answer>\n",
    "            answer_content = match.group(2).strip()\n",
    "\n",
    "            # Check if answer content matches the allowed pattern\n",
    "            if not re.match(allowed_pattern, answer_content):\n",
    "                # If it doesn't match, reward is 0.5\n",
    "                return 0.5\n",
    "            else:\n",
    "                # If both format and pattern are correct, reward is 1\n",
    "                return 1.0\n",
    "    except Exception:\n",
    "        # Any error leads to 0 reward\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def equation_reward_func(completion: str, nums: List[int], target: int) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates completion based on mathematical correctness of the answer\n",
    "\n",
    "    Args:\n",
    "        completion (str): Generated output\n",
    "        target (str): Expected answer\n",
    "        nums (list): Available numbers to use in the equation\n",
    "\n",
    "    Returns:\n",
    "        float: Reward score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the format is correct\n",
    "        match = re.search(r\"<answer>(.*?)<\\/answer>\", completion)\n",
    "        if match is None:\n",
    "            return 0.0\n",
    "        # Extract the \"answer\" part from the completion\n",
    "        equation = match.group(1).strip()\n",
    "        # Extract all numbers from the equation\n",
    "        used_numbers = [int(n) for n in re.findall(r\"\\d+\", equation)]\n",
    "\n",
    "        # Check if all numbers are used exactly once\n",
    "        if sorted(used_numbers) != sorted(nums):\n",
    "            return 0.0\n",
    "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
    "        allowed_pattern = r\"^[\\d+\\-*/().\\s]+$\"\n",
    "        if not re.match(allowed_pattern, equation):\n",
    "            return 0.0\n",
    "\n",
    "        # Evaluate the equation with restricted globals and locals\n",
    "        result = eval(equation, {\"__builtins__\": None}, {})\n",
    "        # Check if the equation is correct and matches the ground truth\n",
    "        if abs(float(result) - float(target)) < 1e-5:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    except Exception:\n",
    "        # If evaluation fails, reward is 0\n",
    "        return 0.0\n",
    "    \n",
    "\n",
    "def compute_reward(completion: str, sample: Dict[str, Any]) -> Tuple[float, Dict[str, float]]:\n",
    "    nums = sample[\"nums\"]\n",
    "    target = sample[\"target\"]\n",
    "\n",
    "    format_reward = format_reward_func(completion)\n",
    "    equation_reward = equation_reward_func(\n",
    "        completion=completion, nums=nums, target=target\n",
    "    )\n",
    "\n",
    "    reward = format_reward + equation_reward\n",
    "\n",
    "    metrics = {\n",
    "        \"format_reward\": format_reward,\n",
    "        \"equation_reward\": equation_reward,\n",
    "    }   \n",
    "\n",
    "    return reward, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <think> is prefilled in the prompt. So, repeating it in the completion would be incorret.\n",
    "format_reward_func(\"<think>I think the answer is </think>\\n<answer>1+2</answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_reward_func(\"I think the answer is </think>\\n<answer>1+2</answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_reward_func(\"<think>I think the<think>and even more</think> answer is </think>\\n<answer>1+2</answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equation_reward_func(\"I think the answer is </think>\\n<answer>1+2+2</answer>\", [1,2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of episode generation is to create a collection of query-response pairs that will be used for policy training. From the reinforcement learning (RL) perspective, the **query** serves as the initial state, and the generated tokens in the **response** represent the actions taken by the policy.\n",
    "\n",
    "The `create_training_episodes` function takes a list of prompts (initial states) and their corresponding completions which we generate using the model.  In GRPO, we always generate multiple responses per prompt—specifically, `GENERATIONS_PER_SAMPLE` > 1. This means that, after episode generation, we end up with `batch_size × GENERATIONS_PER_SAMPLE` episodes in every RL iteration.\n",
    "\n",
    "### Advantage Computation\n",
    "\n",
    "In addition to generating episodes, `create_training_episodes` is also responsible for computing the **advantage** for every response token. \n",
    "\n",
    "In RL terms, the advantage of a token represents how much better or worse that token's action is compared to the average generate token at that specific state (prompt + prefix). Ideally, we would compute an advantage for every token individually to capture how each step contributes to the overall reward.\n",
    "\n",
    "However, in GRPO, there's no per-token advantage computation. Instead, we compute a single advantage value per response. This value reflects how good the entire response is relative to other responses generated for the same prompt. We then assign this single advantage value uniformly to all tokens within that response.\n",
    "\n",
    "GRPO uses a simple formula for this:\n",
    "\n",
    "1. For each prompt $x$ with a group of generated responses $y_1, y_2, \\ldots, y_G \\sim \\pi(\\cdot|x)$, compute their rewards $R_1, R_2, \\ldots, R_G$.\n",
    "2. Compute the group's mean and standard deviation:  \n",
    "   $ \\mu = \\text{mean}(R_1, R_2, \\ldots, R_G) $  \n",
    "   $ \\sigma = \\text{std}(R_1, R_2, \\ldots, R_G) $\n",
    "3. Compute a **relative score** for each response:  \n",
    "   $ R^*_i = \\frac{R_i - \\mu}{\\sigma} $\n",
    "4. Assign this relative score $R^*_i$ as the advantage to all tokens of the $i$-th response:  \n",
    "   $ A_t^{(i)} = R^*_i $\n",
    "\n",
    "This **per-group normalization** encourages responses that are better than average and penalizes those that are worse.\n",
    "\n",
    "### Example: Advantage in Action\n",
    "\n",
    "Consider a binary reward scenario where each response is either correct (1) or incorrect (0):\n",
    "\n",
    "```python\n",
    ">>> rewards = np.array([1, 1, 0, 0, 0])\n",
    ">>> (rewards - rewards.mean()) / (rewards.std())\n",
    "array([ 1.22474487,  1.22474487, -0.81649658, -0.81649658, -0.81649658])\n",
    "```\n",
    "\n",
    "Here, the correct responses receive higher advantage scores, promoting them in future updates.\n",
    "\n",
    "\n",
    "If only one response is correct:\n",
    "\n",
    "```python\n",
    ">>> rewards = np.array([1, 0, 0, 0, 0])\n",
    ">>> (rewards - rewards.mean()) / (rewards.std())\n",
    "array([ 2. , -0.5, -0.5, -0.5, -0.5])\n",
    "```\n",
    "\n",
    "This resembles the case where the question in the prompt is too hard and the model is not able to generate a correct response on average.\n",
    "However, if one of the responses is correct, it will be assigned a higher advantage score, and all incorrect responses will be assigned a negative relative score.\n",
    "\n",
    "If all responses are incorrect:\n",
    "\n",
    "```python\n",
    ">>> rewards = np.array([0, 0, 0, 0, 0])\n",
    ">>> (rewards - rewards.mean()) / (rewards.std() + 1e-6)\n",
    "array([0., 0., 0., 0., 0.])\n",
    "```\n",
    "\n",
    "Since there is no one is better than the average, the model receives no learning signal.\n",
    "\n",
    "If all responses are correct:\n",
    "\n",
    "```python\n",
    ">>> rewards = np.array([1, 1, 1, 1, 1])\n",
    ">>> (rewards - rewards.mean()) / (rewards.std() + 1e-6)\n",
    "array([0., 0., 0., 0., 0.])\n",
    "```\n",
    "\n",
    "Again, no learning signal is provided because there is nothing to improve upon.\n",
    "\n",
    "In a more mixed case:\n",
    "\n",
    "```python\n",
    ">>> rewards = np.array([1, 1, 1, 1, 0])\n",
    ">>> (rewards - rewards.mean()) / (rewards.std() + 1e-6)\n",
    "array([0.5, 0.5, 0.5, 0.5, -2.])\n",
    "```\n",
    "\n",
    "This represents an easier question for the model. Most responses are correct, but occasional incorrect ones are heavily penalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_episodes(\n",
    "    samples: List[Dict[str, Any]],\n",
    "    all_generations: List[List[int]],\n",
    "    all_finish_reasons: List[str],\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process model generations and calculate rewards for training episodes.\n",
    "\n",
    "    This function processes generated responses and calculates rewards for training episodes by:\n",
    "    1. Grouping generations by sample (GENERATIONS_PER_SAMPLE responses per input)\n",
    "    2. Computing rewards and advantages for each response\n",
    "    3. Processing response tokens\n",
    "\n",
    "    Args:\n",
    "        samples: List of input samples, each containing:\n",
    "            - input_ids: List[int], tokenized input prompt\n",
    "            - nums: List[int], numbers to use in equation\n",
    "            - target: int, target value for equation\n",
    "        all_generations: List of token ID sequences for each generated response\n",
    "        all_finish_reasons: List of finish reasons for each generation (\"stop\" or other)\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        1. Dictionary with processed data for training:\n",
    "            - all_query_token_ids: List[List[int]], input token IDs repeated for each generation\n",
    "            - all_response_token_ids: List[List[int]], response token IDs with EOS tokens added\n",
    "            - all_advantages: List[List[float]], advantage values repeated for each token\n",
    "        2. Dictionary with generation statistics:\n",
    "            - response_lengths: List[int], lengths of generated responses\n",
    "            - rewards: List[float], raw reward values\n",
    "            - non_stop_rate: List[bool], whether each generation ended naturally\n",
    "            - reward_metrics/*: Various reward component metrics\n",
    "\n",
    "    Example:\n",
    "        >>> samples = [{\"input_ids\": [1,2,3], \"nums\": [1,2,3], \"target\": 6}]\n",
    "        >>> generations = [[4,5, EOS_TOKEN_ID], [6,7], [8,9, EOS_TOKEN_ID]]  # 3 generations per sample\n",
    "        >>> finish_reasons = [\"stop\", \"length\", \"stop\"]\n",
    "        >>> episodes, stats = create_training_episodes(samples, generations, finish_reasons)\n",
    "        >>> episodes\n",
    "        {\n",
    "            'all_query_token_ids': [[1,2,3], [1,2,3], [1,2,3]],\n",
    "            'all_response_token_ids': [[4,5,EOS_TOKEN_ID], [6,7], [8,9,EOS_TOKEN_ID]],\n",
    "            'all_advantages': [[0.5,0.5,0.5], [-1.0,-1.0], [0.5,0.5,0.5]]\n",
    "        }\n",
    "    \"\"\"\n",
    "    assert len(all_generations) == len(all_finish_reasons)\n",
    "    assert len(all_generations) == len(samples) * GENERATIONS_PER_SAMPLE\n",
    "\n",
    "    # Process responses and calculate rewards\n",
    "    groups = [\n",
    "        list(range(i, i + GENERATIONS_PER_SAMPLE))\n",
    "        for i in range(0, len(all_generations), GENERATIONS_PER_SAMPLE)\n",
    "    ]  # example: [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "\n",
    "    all_query_token_ids, all_responses_token_ids, all_advantages = [], [], []\n",
    "\n",
    "    stats = {\n",
    "        \"response_lengths\": [],\n",
    "        \"rewards\": [],\n",
    "        \"non_stop_rate\": [],\n",
    "    }\n",
    "\n",
    "    for sample, group_indices in zip(samples, groups):\n",
    "        finish_reasons = [all_finish_reasons[i] for i in group_indices]\n",
    "        response_token_ids = [all_generations[i] for i in group_indices]\n",
    "        responses = tokenizer.batch_decode(response_token_ids, skip_special_tokens=False)\n",
    "\n",
    "        rewards_and_metrics = [compute_reward(resp, sample) for resp in responses]\n",
    "        rewards, reward_metrics = zip(*rewards_and_metrics)\n",
    "\n",
    "        rewards = np.array(rewards) # [group_size]\n",
    "        response_advantages = (rewards - rewards.mean()) / (rewards.std() + 1e-4)\n",
    "        \n",
    "        advantages = [\n",
    "            [resp_adv] * len(resp) \n",
    "            for resp_adv, resp in zip(response_advantages, response_token_ids)\n",
    "        ]\n",
    "\n",
    "        all_query_token_ids.extend([sample[\"input_ids\"]] * GENERATIONS_PER_SAMPLE)\n",
    "        all_responses_token_ids.extend(response_token_ids)\n",
    "        all_advantages.extend(advantages)\n",
    "\n",
    "        stats[\"rewards\"].extend(rewards)\n",
    "        stats[\"non_stop_rate\"].extend([fr != \"stop\" for fr in finish_reasons])\n",
    "        stats[\"response_lengths\"].extend([len(ids) for ids in response_token_ids])\n",
    "        for rm in reward_metrics:\n",
    "            for k, v in rm.items():\n",
    "                stats.setdefault(f\"reward_metrics/{k}\", []).append(v)\n",
    "\n",
    "    episodes = {\n",
    "        \"all_query_token_ids\": all_query_token_ids,\n",
    "        \"all_response_token_ids\": all_responses_token_ids,\n",
    "        \"all_advantages\": all_advantages,\n",
    "    }\n",
    "\n",
    "    return episodes, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_query_token_ids': [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]],\n",
       " 'all_response_token_ids': [[4, 5, 22, 33], [6, 7], [8, 9, 11], [10, 11]],\n",
       " 'all_advantages': [[np.float64(0.0),\n",
       "   np.float64(0.0),\n",
       "   np.float64(0.0),\n",
       "   np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_0 = {\n",
    "    \"sample\": {\"input_ids\": [1,2,3], \"nums\": [1,2,3], \"target\": 6},\n",
    "    \"generations\": [[4,5, 22, 33], [6,7], [8,9, 11], [10,11]],\n",
    "    \"finish_reasons\": [\"stop\", \"length\", \"stop\", \"stop\"]\n",
    "}\n",
    "\n",
    "case = case_0\n",
    "episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_query_token_ids': [[33, 44], [33, 44], [33, 44], [33, 44]],\n",
       " 'all_response_token_ids': [[1, 2], [3, 4], [5, 6], [7, 8]],\n",
       " 'all_advantages': [[np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_1 = {\n",
    "    \"sample\": {\"input_ids\": [33, 44], \"nums\": [11, 7, 8], \"target\": 26},\n",
    "    \"generations\": [[1,2], [3,4], [5,6], [7,8]],\n",
    "    \"finish_reasons\": [\"stop\", \"stop\", \"length\", \"stop\"]\n",
    "}\n",
    "case = case_1\n",
    "episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_query_token_ids': [[9, 8, 7, 6, 5, 4],\n",
       "  [9, 8, 7, 6, 5, 4],\n",
       "  [9, 8, 7, 6, 5, 4],\n",
       "  [9, 8, 7, 6, 5, 4]],\n",
       " 'all_response_token_ids': [[9, 10], [11, 12], [13, 14], [15, 16]],\n",
       " 'all_advantages': [[np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)],\n",
       "  [np.float64(0.0), np.float64(0.0)]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2 = {\n",
    "    \"sample\": {\"input_ids\": [9, 8, 7, 6, 5, 4], \"nums\": [1,2,3,4], \"target\": 10},\n",
    "    \"generations\": [[9,10], [11,12], [13,14], [15,16]],\n",
    "    \"finish_reasons\": [\"length\", \"length\", \"stop\", \"stop\"]\n",
    "}\n",
    "case = case_2\n",
    "episodes, stats = create_training_episodes([case[\"sample\"]], case[\"generations\"], case[\"finish_reasons\"])\n",
    "episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `input_ids` of this single exmaple is repeated in all of generated episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have a batch of episodes with corresponding advantages, we can compute the **policy gradient loss** to update the model.\n",
    "\n",
    "GRPO uses the same loss formulation as PPO, but the key difference lies in how advantages are computed. To understand the implementation in `compute_pg_loss`, let’s first recall the original PPO objective:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{PPO}} = \\mathbb{E}\\left[\\min\\left( \n",
    "\\frac{\\pi_\\theta(y_t \\mid y_{<t}, x)}{\\pi_{\\theta_{\\text{old}}}(y_t \\mid y_{<t}, x)} A_t, \\;\n",
    "\\text{clip}\\left(\n",
    "\\frac{\\pi_\\theta(y_t \\mid y_{<t}, x)}{\\pi_{\\theta_{\\text{old}}}(y_t \\mid y_{<t}, x)}, \\;\n",
    "1 - \\epsilon, \\; 1 + \\epsilon\n",
    "\\right) A_t \\right)\\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\pi_{\\theta} $ is the current policy,\n",
    "- $ \\pi_{\\theta_{\\text{old}}} $ is the policy from the previous iteration (the policy we sampled episodes from),\n",
    "- $ A_t $ is the advantage.\n",
    "\n",
    "This objective tries to increase or decrease the probability of tokens based on the advantage $A_t$ only when the ratio between the new and old policy probabilities stays within a small range, controlled by the clipping threshold $\\epsilon$. This clipping mechanism prevents large, destabilizing updates during training.\n",
    "\n",
    "### Fully Online Setting: Simplifying the Objective\n",
    "\n",
    "In general PPO, multiple gradient steps might be taken using the same batch of episodes. However, in our case, we apply only **one gradient step per iteration** using freshly sampled episodes. That means:\n",
    "\n",
    "- $ \\pi_{\\theta} = \\pi_{\\theta_{\\text{old}}} $\n",
    "- Consequently,  \n",
    "  $$\n",
    "  \\frac{\\pi_\\theta(y_t \\mid y_{<t}, x)}{\\pi_{\\theta_{\\text{old}}}(y_t \\mid y_{<t}, x)} = 1\n",
    "  $$\n",
    "  \n",
    "Since the ratio is exactly 1:\n",
    "- The clipping function becomes inactive.\n",
    "- The $\\min(\\cdot,\\cdot)$ operator simply returns the unclipped term.\n",
    "\n",
    "So, the objective simplifies **to**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{PPO}} = \\mathbb{E}\\left[ \\frac{\\pi_\\theta(y_t \\mid y_{<t}, x)}{\\pi_{\\theta_{\\text{old}}}(y_t \\mid y_{<t}, x)} A_t \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Taking the gradient of this loss with respect to $\\theta$, we get:\n",
    "\n",
    "$$\n",
    "\\vec{g}_{\\text{PPO}} = \\nabla_\\theta \\mathcal{L}_{\\text{PPO}} = 2 \\underbrace{\\mathbb{E}\\left[ \\nabla_\\theta \\log \\pi_\\theta(y_t \\mid y_{<t}, x) \\cdot A_t \\right]}_{\\text{vanilla policy gradient with advantage}}\n",
    "$$\n",
    "\n",
    "This is the **standard policy gradient** formula, where the log-probabilities are weighted by the advantage. In effect, we recover vanilla REINFORCE-style learning.\n",
    "\n",
    "> Note: The a constant multiplier (like 2) does not affect the direction of the gradient and can be safely ignored.\n",
    "\n",
    "In fact, this behavior is not unique to GRPO. In all methods such as PPO, TRPO the very first gradient step after collecting new data will always reduce to this same form. Only after the optimization step the clipping or trust region constraint start to take effect.\n",
    "\n",
    "### KL Penalty\n",
    "\n",
    "The final loss also has a **KL penalty** term to ensure the new policy doesn't drift too far from a reference policy:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathcal{L}_{\\text{PPO}} - \\beta \\cdot \\text{KL}(\\pi_\\theta \\parallel \\pi_{\\theta_{\\text{ref}}})\n",
    "$$\n",
    "\n",
    "We estimate the KL divergence using the **k3 estimator** from [this blog post by Schulman](http://joschu.net/blog/kl-approx.html):\n",
    "\n",
    "$$\n",
    "\\text{KL}(\\pi_\\theta \\parallel \\pi_{\\theta_{\\text{ref}}}) = \\mathbb{E}\\left[\\frac{\\pi_{\\theta_{\\text{ref}}}(y_t \\mid y_{<t}, x)}{\\pi_\\theta(y_t \\mid y_{<t}, x)} - \\log\\left(\\frac{\\pi_{\\theta_{\\text{ref}}}(y_t \\mid y_{<t}, x)}{\\pi_\\theta(y_t \\mid y_{<t}, x)}\\right) - 1\\right]\n",
    "$$\n",
    "\n",
    "This regularization term softly constrains the updated model to remain close to the reference.\n",
    "\n",
    "\n",
    "### GRPO vs PPO/VinePPO: Key Difference\n",
    "\n",
    "The main difference between **GRPO** and methods like **PPO/VinePPO** lies in **how the advantage is computed and applied**:\n",
    "\n",
    "- In **PPO/VinePPO**, each token/step's advantage is computed individually. This allows for fine-grained credit assignment across the sequence.\n",
    "- In **GRPO**, a **single scalar advantage** is computed for the entire response and is applied **uniformly to all tokens** in that response.\n",
    "\n",
    "This distinction is illustrated below:\n",
    "\n",
    "#### A successful response in GRPO:\n",
    "<img src=\"https://github.com/McGill-NLP/nano-aha-moment/blob/main/assets/grpo_successful.png?raw=true\" alt=\"GRPO vs PPO/VinePPO: successful response\" width=\"500\">\n",
    "\n",
    "#### A failed response in GRPO:\n",
    "<img src=\"https://github.com/McGill-NLP/nano-aha-moment/blob/main/assets/grpo_unsuccessful.png?raw=true\" alt=\"GRPO vs PPO/VinePPO: failed response\" width=\"500\">\n",
    "\n",
    "In GRPO, all tokens in a response are updated with the same magnitude. In contrast, PPO/VinePPO updates each token/step with a different advantage value:\n",
    "\n",
    "<img src=\"https://github.com/McGill-NLP/nano-aha-moment/blob/main/assets/ppo_and_vineppo.png?raw=true\" alt=\"GRPO vs PPO/VinePPO: PPO and VinePPO\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pg_loss(\n",
    "    policy_model: Union[DeepSpeedEngine, PreTrainedModel],\n",
    "    reference_model: Union[DeepSpeedEngine, PreTrainedModel],\n",
    "    batch: Dict[str, torch.Tensor],\n",
    "    total_response_len: int,\n",
    ") -> Tuple[torch.Tensor, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute the policy gradient loss with KL penalty between policy and reference models.\n",
    "\n",
    "    This function:\n",
    "    1. Computes log probabilities for both policy and reference models\n",
    "    2. Calculates KL divergence penalty between the models\n",
    "    3. Computes policy gradient loss using advantages\n",
    "    4. Combines the losses with KL coefficient\n",
    "\n",
    "    Args:\n",
    "        policy_model: The model being trained\n",
    "        reference_model: The reference model for KL penalty calculation\n",
    "        batch: Dictionary containing:\n",
    "            - input_ids: Tensor of shape [batch_size, seq_len]\n",
    "            - attention_mask: Tensor of shape [batch_size, seq_len]\n",
    "            - labels: Tensor of shape [batch_size, seq_len] with -100 for ignored positions\n",
    "            - advantages: Tensor of shape [batch_size, seq_len]\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - loss: Combined policy gradient and KL penalty loss (scalar tensor)\n",
    "            - metrics: Dictionary with detailed loss components:\n",
    "                - policy_loss: Pure policy gradient loss\n",
    "                - kl_penalty: KL divergence penalty\n",
    "                - entropy: Policy entropy\n",
    "    \"\"\"\n",
    "    input_ids = batch[\"input_ids\"]  # [batch_size, seq_len]\n",
    "    attention_mask = batch[\"attention_mask\"]  # [batch_size, seq_len]\n",
    "    labels = batch[\"labels\"]  # [batch_size, seq_len]\n",
    "    advantages = batch[\"advantages\"]  # [batch_size, seq_len]\n",
    "    labels_mask = batch[\"labels_mask\"]\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"labels_mask\": labels_mask, \n",
    "    }\n",
    "\n",
    "    labels_mask = (labels[..., 1:] != -100).float()  # [batch_size, seq_len-1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_logps = compute_token_log_probs(\n",
    "            reference_model, model_inputs, TEMPERATURE\n",
    "        )  # [batch_size, seq_len-1]\n",
    "\n",
    "    logps = compute_token_log_probs(policy_model, model_inputs, TEMPERATURE)  # [batch_size, seq_len-1]\n",
    "\n",
    "    kl_penalty = torch.exp(ref_logps - logps) - (ref_logps - logps) - 1  # [batch_size, seq_len-1]\n",
    "    kl_penalty = kl_penalty * labels_mask  # [batch_size, seq_len-1]\n",
    "\n",
    "    entropy = -logps.sum() / labels_mask.sum()  # scalar\n",
    "\n",
    "    policy_loss = -logps * advantages[..., 1:]  # [batch_size, seq_len-1]\n",
    "    policy_loss = policy_loss * labels_mask  # [batch_size, seq_len-1]\n",
    "\n",
    "    loss = (policy_loss + KL_COEFFICIENT * kl_penalty).sum() / total_response_len  # scalar\n",
    "\n",
    "    metrics = {\n",
    "        \"policy_loss\": policy_loss.sum().item() / total_response_len,\n",
    "        \"kl_penalty\": kl_penalty.sum().item() / total_response_len,\n",
    "        \"entropy\": entropy.item() / total_response_len,\n",
    "    }\n",
    "\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reimport \n",
    "import utils \n",
    "from utils import (\n",
    "    compute_token_log_probs,\n",
    "    dump_episodes,\n",
    "    evaluate_on_test_set,\n",
    "    find_free_port,\n",
    "    find_last_checkpoint,\n",
    "    prepare_model_inputs,\n",
    "    load_model_into_vllm\n",
    ")\n",
    "\n",
    "import vllm_utils \n",
    "\n",
    "from vllm.utils.network_utils import (\n",
    "    get_open_port, \n",
    "    get_ip\n",
    ")\n",
    "\n",
    "from vllm_utils import (\n",
    "    stateless_init_process_group, \n",
    "    WorkerExtension, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils \n",
    "\n",
    "from vllm.inputs import TokensPrompt\n",
    "importlib.reload(utils)\n",
    "from utils import (\n",
    "    compute_token_log_probs,\n",
    "    dump_episodes,\n",
    "    evaluate_on_test_set,\n",
    "    find_free_port,\n",
    "    find_last_checkpoint,\n",
    "    prepare_model_inputs,\n",
    "    load_model_into_vllm\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def load_model_into_vllm(model: Union[DeepSpeedEngine, PreTrainedModel], communicator, llm: LLM) -> None:\n",
      "    \"\"\"\n",
      "    Load weights from a HuggingFace model (either wrapped in DeepSpeed or not) into a vLLM inference engine.\n",
      "\n",
      "    This function transfers the weights from a training model to a vLLM inference engine,\n",
      "    allowing for efficient inference using the updated model weights.\n",
      "\n",
      "    Args:\n",
      "        model (Union[DeepSpeedEngine, PreTrainedModel]): The source model to copy weights from.\n",
      "            Can be either a DeepSpeed-wrapped model or a regular HuggingFace PreTrainedModel.\n",
      "        vllm (LLM): The target vLLM inference engine to load the weights into.\n",
      "            Must be already initialized and ready to accept new weights.\n",
      "\n",
      "    Returns:\n",
      "        None\n",
      "    \"\"\"\n",
      "\n",
      "    for name, p in model.named_parameters():\n",
      "        dtype_name = str(p.dtype).split(\".\")[-1]\n",
      "        if \"module\" in name:\n",
      "            name = name.replace(\"module.\", \"\")\n",
      "\n",
      "        handle = llm.collective_rpc.remote(\n",
      "            \"update_weight\", args=(name, dtype_name, p.shape)\n",
      "        )\n",
      "        communicator.broadcast(p, src=0, stream=torch.cuda.current_stream())\n",
      "        ray.get(handle)\n",
      "\n",
      "    # outdated vllm method of loading weights into inference engine: \n",
      "    # state_dict = model.module.state_dict() if isinstance(model, DeepSpeedEngine) else model.state_dict()\n",
      "    # llm.llm_engine.model_executor.driver_worker.model_runner.model.load_weights(state_dict.items())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect \n",
    "print(inspect.getsource(load_model_into_vllm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Transfer Infra \n",
    "\n",
    "Using Ray and VLLM collective RPCs, we can establish a communication process group between our hugging-face transformers instance (for training, contains gradient/backprop info) and the VLLM inference engines \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import torch\n",
    "from ray.util.placement_group import placement_group\n",
    "from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy\n",
    "from vllm_utils import stateless_init_process_group\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.utils.network_utils import get_ip, get_open_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3,4,5\n",
      "3,4,5\n"
     ]
    }
   ],
   "source": [
    "# check world is property init \n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=3,4,5\n",
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.69it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let us initialize the huggingface models (policy and reference) \n",
    "\n",
    "policy_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=0,\n",
    ")\n",
    "reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=0,\n",
    ")\n",
    "policy_model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "\n",
    "\n",
    "# Initialize DeepSpeed engines\n",
    "policy_model, *_ = deepspeed.initialize(\n",
    "    model=policy_model,\n",
    "    config=deepspeed_config,\n",
    "    model_parameters=policy_model.parameters(),\n",
    ")\n",
    "reference_model, *_ = deepspeed.initialize(\n",
    "    model=reference_model,\n",
    "    config=ref_deepspeed_config,\n",
    ")\n",
    "\n",
    "reference_model.module.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model we initialized above sits on the first gpu of our world (gpu 3). For the VLLM engines, we define the next two gpus as their world and initialize our Ray server on them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 01:11:48,503\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.19</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.48.0</b></td>\n",
       "    </tr>\n",
       "    \n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.19', ray_version='2.48.0', ray_commit='03491225d59a1ffde99c3628969ccf456be13efd')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=660219)\u001b[0m WARNING 12-04 01:11:57 [cuda.py:608] Detected different devices in the system: NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [utils.py:253] non-default args: {'dtype': torch.bfloat16, 'max_model_len': 2048, 'distributed_executor_backend': 'ray', 'tensor_parallel_size': 2, 'enable_prefix_caching': True, 'swap_space': 1, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enforce_eager': True, 'worker_extension_cls': 'vllm_utils.WorkerExtension', 'enable_sleep_mode': True, 'model': 'Qwen/Qwen2.5-3B'}\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [model.py:631] Resolved architecture: Qwen2ForCausalLM\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [model.py:1745] Using max model len 2048\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [arg_utils.py:1443] Using ray runtime env (env vars redacted): {}\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:00 [vllm.py:500] Cudagraph is disabled under eager mode\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m WARNING 12-04 01:12:01 [system_utils.py:103] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m WARNING 12-04 01:12:05 [cuda.py:608] Detected different devices in the system: NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen2.5-3B', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen2.5-3B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:06 [ray_utils.py:374] Using the existing placement group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m 2025-12-04 01:12:06,915\tINFO worker.py:1606 -- Using address 128.2.204.135:55805 set in the environment variable RAY_ADDRESS\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m 2025-12-04 01:12:06,926\tINFO worker.py:1747 -- Connecting to existing Ray cluster at address: 128.2.204.135:55805...\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m 2025-12-04 01:12:06,939\tINFO worker.py:1927 -- Connected to Ray cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(pid=660235)\u001b[0m WARNING 12-04 01:12:10 [cuda.py:608] Detected different devices in the system: NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:12 [ray_env.py:66] RAY_NON_CARRY_OVER_ENV_VARS from config: set()\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:12 [ray_env.py:69] Copying the following environment variables to workers: ['VLLM_WORKER_MULTIPROC_METHOD']\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:12 [ray_env.py:74] If certain env vars should NOT be copied, add them to /home/kailash/.config/vllm/ray_non_carry_over_env_vars.json file\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:13 [worker_base.py:283] Injected <class 'vllm_utils.WorkerExtension'> into <class 'vllm.v1.worker.gpu_worker.Worker'> for extended collective_rpc calls ['check_weights_changed', 'init_weight_update_group', 'update_weight']\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m WARNING 12-04 01:12:13 [worker_base.py:301] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:13 [parallel_state.py:1208] world_size=2 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:50557 backend=nccl\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:14 [pynccl.py:111] vLLM is using nccl==2.27.5\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m WARNING 12-04 01:12:14 [symm_mem.py:67] SymmMemCommunicator: Device capability 8.0 not supported, communicator is not available.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:15 [parallel_state.py:1394] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen2.5-3B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m /home/kailash/miniconda3/envs/vllm/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:161: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:15 [cuda.py:427] Using FLASH_ATTN backend.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(pid=660221)\u001b[0m WARNING 12-04 01:12:10 [cuda.py:608] Detected different devices in the system: NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A100 80GB PCIe, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active, NVIDIA A800 40GB Active. Please make sure to set `CUDA_DEVICE_ORDER=PCI_BUS_ID` to avoid unexpected behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]ayWorkerWrapper pid=660221)\u001b[0m \n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.44it/s]Wrapper pid=660221)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:17 [default_loader.py:314] Loading weights took 0.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.78it/s]Wrapper pid=660221)\u001b[0m \n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.72it/s]Wrapper pid=660221)\u001b[0m \n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:18 [gpu_model_runner.py:3338] Model loading took 2.9348 GiB memory and 1.618970 seconds\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660221)\u001b[0m INFO 12-04 01:12:24 [gpu_worker.py:359] Available KV cache memory: 18.95 GiB\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m INFO 12-04 01:12:13 [worker_base.py:283] Injected <class 'vllm_utils.WorkerExtension'> into <class 'vllm.v1.worker.gpu_worker.Worker'> for extended collective_rpc calls ['check_weights_changed', 'init_weight_update_group', 'update_weight']\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m WARNING 12-04 01:12:13 [worker_base.py:301] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m INFO 12-04 01:12:13 [parallel_state.py:1208] world_size=2 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:50557 backend=nccl\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\u001b[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m WARNING 12-04 01:12:14 [symm_mem.py:67] SymmMemCommunicator: Device capability 8.0 not supported, communicator is not available.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m INFO 12-04 01:12:15 [parallel_state.py:1394] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m INFO 12-04 01:12:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=660235)\u001b[0m INFO 12-04 01:12:16 [cuda.py:427] Using FLASH_ATTN backend.\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:25 [kv_cache_utils.py:1229] GPU KV cache size: 1,104,032 tokens\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:25 [kv_cache_utils.py:1234] Maximum concurrency for 2,048 tokens per request: 539.08x\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:25 [kv_cache_utils.py:1234] Maximum concurrency for 2,048 tokens per request: 539.08x\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:25 [core.py:250] init engine (profile, create kv cache, warmup model) took 7.10 seconds\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:26 [vllm.py:500] Cudagraph is disabled under eager mode\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m INFO 12-04 01:12:26 [llm.py:352] Supported tasks: ['generate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 4/4 [00:00<00:00, 1752.01it/s]\n",
      "Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:26 [ray_executor.py:538] RAY_CGRAPH_get_timeout is set to 300\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:26 [ray_executor.py:542] VLLM_USE_RAY_COMPILED_DAG_CHANNEL_TYPE = auto\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:26 [ray_executor.py:546] VLLM_USE_RAY_COMPILED_DAG_OVERLAP_COMM = False\n",
      "\u001b[36m(MyLLM pid=660219)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=666837)\u001b[0;0m INFO 12-04 01:12:26 [ray_executor.py:605] Using RayPPCommunicator (which wraps vLLM _PP GroupCoordinator) for Ray Compiled Graph communication.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00,  7.80it/s, est. speed input: 42.91 toks/s, output: 124.83 toks/s]\n",
      "Adding requests: 100%|██████████| 500/500 [00:00<00:00, 8931.88it/s]\n",
      "Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   0%|          | 1/500 [00:03<26:03,  3.13s/it, est. speed input: 45.01 toks/s, output: 27.13 toks/s]\n",
      "Processed prompts:   1%|          | 4/500 [00:03<05:13,  1.58it/s, est. speed input: 172.66 toks/s, output: 105.85 toks/s]\n",
      "Processed prompts:   1%|▏         | 7/500 [00:03<02:36,  3.14it/s, est. speed input: 290.31 toks/s, output: 183.01 toks/s]\n",
      "Processed prompts:   2%|▏         | 10/500 [00:03<01:38,  4.98it/s, est. speed input: 400.60 toks/s, output: 257.99 toks/s]\n",
      "Processed prompts:   2%|▏         | 12/500 [00:03<01:23,  5.83it/s, est. speed input: 453.45 toks/s, output: 300.70 toks/s]\n",
      "Processed prompts:   3%|▎         | 17/500 [00:03<00:48,  9.86it/s, est. speed input: 614.92 toks/s, output: 427.90 toks/s]\n",
      "Processed prompts:   5%|▍         | 23/500 [00:04<00:30, 15.78it/s, est. speed input: 807.14 toks/s, output: 585.93 toks/s]\n",
      "Processed prompts:   6%|▌         | 31/500 [00:04<00:19, 24.59it/s, est. speed input: 1054.79 toks/s, output: 798.57 toks/s]\n",
      "Processed prompts:   7%|▋         | 36/500 [00:04<00:17, 26.75it/s, est. speed input: 1183.14 toks/s, output: 914.87 toks/s]\n",
      "Processed prompts:   8%|▊         | 40/500 [00:04<00:17, 26.82it/s, est. speed input: 1271.90 toks/s, output: 1000.21 toks/s]\n",
      "Processed prompts:   9%|▉         | 45/500 [00:04<00:15, 28.69it/s, est. speed input: 1387.20 toks/s, output: 1113.78 toks/s]\n",
      "Processed prompts:  10%|█         | 51/500 [00:04<00:14, 32.05it/s, est. speed input: 1523.25 toks/s, output: 1254.02 toks/s]\n",
      "Processed prompts:  12%|█▏        | 60/500 [00:04<00:10, 41.79it/s, est. speed input: 1743.52 toks/s, output: 1486.41 toks/s]\n",
      "Processed prompts:  13%|█▎        | 66/500 [00:05<00:11, 39.14it/s, est. speed input: 1850.42 toks/s, output: 1610.58 toks/s]\n",
      "Processed prompts:  15%|█▍        | 73/500 [00:05<00:09, 43.64it/s, est. speed input: 1997.57 toks/s, output: 1780.13 toks/s]\n",
      "Processed prompts:  16%|█▌        | 78/500 [00:05<00:11, 36.53it/s, est. speed input: 2053.95 toks/s, output: 1861.78 toks/s]\n",
      "Processed prompts:  17%|█▋        | 83/500 [00:05<00:13, 30.78it/s, est. speed input: 2094.07 toks/s, output: 1932.45 toks/s]\n",
      "Processed prompts:  17%|█▋        | 87/500 [00:05<00:13, 29.98it/s, est. speed input: 2141.19 toks/s, output: 2004.58 toks/s]\n",
      "Processed prompts:  18%|█▊        | 92/500 [00:05<00:12, 32.77it/s, est. speed input: 2218.79 toks/s, output: 2115.46 toks/s]\n",
      "Processed prompts:  19%|█▉        | 96/500 [00:06<00:12, 31.33it/s, est. speed input: 2260.60 toks/s, output: 2171.83 toks/s]\n",
      "Processed prompts:  20%|██        | 101/500 [00:06<00:14, 27.42it/s, est. speed input: 2288.77 toks/s, output: 2240.61 toks/s]\n",
      "Processed prompts:  21%|██        | 104/500 [00:06<00:14, 26.94it/s, est. speed input: 2313.69 toks/s, output: 2290.83 toks/s]\n",
      "Processed prompts:  22%|██▏       | 108/500 [00:06<00:14, 26.94it/s, est. speed input: 2347.67 toks/s, output: 2360.51 toks/s]\n",
      "Processed prompts:  22%|██▏       | 111/500 [00:06<00:14, 26.63it/s, est. speed input: 2370.78 toks/s, output: 2396.77 toks/s]\n",
      "Processed prompts:  23%|██▎       | 115/500 [00:06<00:13, 28.64it/s, est. speed input: 2414.02 toks/s, output: 2465.25 toks/s]\n",
      "Processed prompts:  25%|██▍       | 123/500 [00:06<00:09, 38.67it/s, est. speed input: 2537.89 toks/s, output: 2667.08 toks/s]\n",
      "Processed prompts:  25%|██▌       | 127/500 [00:07<00:10, 35.05it/s, est. speed input: 2565.49 toks/s, output: 2718.98 toks/s]\n",
      "Processed prompts:  27%|██▋       | 133/500 [00:07<00:09, 39.00it/s, est. speed input: 2641.01 toks/s, output: 2809.63 toks/s]\n",
      "Processed prompts:  28%|██▊       | 138/500 [00:07<00:09, 37.26it/s, est. speed input: 2684.16 toks/s, output: 2887.23 toks/s]\n",
      "Processed prompts:  28%|██▊       | 142/500 [00:07<00:13, 27.46it/s, est. speed input: 2666.80 toks/s, output: 2897.10 toks/s]\n",
      "Processed prompts:  29%|██▉       | 146/500 [00:07<00:12, 28.78it/s, est. speed input: 2698.53 toks/s, output: 2945.77 toks/s]\n",
      "Processed prompts:  30%|███       | 152/500 [00:07<00:10, 31.78it/s, est. speed input: 2754.25 toks/s, output: 3042.89 toks/s]\n",
      "Processed prompts:  32%|███▏      | 158/500 [00:07<00:09, 36.11it/s, est. speed input: 2819.65 toks/s, output: 3166.73 toks/s]\n",
      "Processed prompts:  32%|███▏      | 162/500 [00:08<00:10, 33.51it/s, est. speed input: 2839.35 toks/s, output: 3218.77 toks/s]\n",
      "Processed prompts:  33%|███▎      | 166/500 [00:08<00:16, 20.56it/s, est. speed input: 2769.99 toks/s, output: 3168.96 toks/s]\n",
      "Processed prompts:  34%|███▍      | 169/500 [00:08<00:16, 19.69it/s, est. speed input: 2763.45 toks/s, output: 3163.90 toks/s]\n",
      "Processed prompts:  34%|███▍      | 172/500 [00:08<00:19, 16.75it/s, est. speed input: 2728.55 toks/s, output: 3113.59 toks/s]\n",
      "Processed prompts:  35%|███▌      | 175/500 [00:09<00:24, 13.38it/s, est. speed input: 2669.55 toks/s, output: 3059.34 toks/s]\n",
      "Processed prompts:  36%|███▌      | 181/500 [00:09<00:17, 17.73it/s, est. speed input: 2707.21 toks/s, output: 3111.05 toks/s]\n",
      "Processed prompts:  37%|███▋      | 186/500 [00:09<00:14, 21.73it/s, est. speed input: 2745.39 toks/s, output: 3160.84 toks/s]\n",
      "Processed prompts:  39%|███▊      | 193/500 [00:09<00:10, 28.59it/s, est. speed input: 2811.43 toks/s, output: 3285.73 toks/s]\n",
      "Processed prompts:  40%|███▉      | 198/500 [00:09<00:10, 28.25it/s, est. speed input: 2831.44 toks/s, output: 3321.68 toks/s]\n",
      "Processed prompts:  41%|████      | 203/500 [00:10<00:09, 30.96it/s, est. speed input: 2866.72 toks/s, output: 3368.20 toks/s]\n",
      "Processed prompts:  41%|████▏     | 207/500 [00:10<00:12, 22.56it/s, est. speed input: 2832.59 toks/s, output: 3326.94 toks/s]\n",
      "Processed prompts:  42%|████▏     | 210/500 [00:10<00:15, 19.31it/s, est. speed input: 2809.19 toks/s, output: 3306.75 toks/s]\n",
      "Processed prompts:  43%|████▎     | 213/500 [00:10<00:15, 18.51it/s, est. speed input: 2800.66 toks/s, output: 3314.80 toks/s]\n",
      "Processed prompts:  43%|████▎     | 216/500 [00:11<00:17, 16.60it/s, est. speed input: 2779.44 toks/s, output: 3322.30 toks/s]\n",
      "Processed prompts:  44%|████▍     | 222/500 [00:11<00:13, 21.02it/s, est. speed input: 2810.88 toks/s, output: 3356.93 toks/s]\n",
      "Processed prompts:  45%|████▌     | 225/500 [00:11<00:14, 18.52it/s, est. speed input: 2792.01 toks/s, output: 3344.00 toks/s]\n",
      "Processed prompts:  46%|████▌     | 228/500 [00:11<00:17, 15.21it/s, est. speed input: 2755.83 toks/s, output: 3303.62 toks/s]\n",
      "Processed prompts:  47%|████▋     | 233/500 [00:11<00:14, 18.73it/s, est. speed input: 2778.22 toks/s, output: 3340.73 toks/s]\n",
      "Processed prompts:  47%|████▋     | 236/500 [00:12<00:15, 17.36it/s, est. speed input: 2764.77 toks/s, output: 3368.50 toks/s]\n",
      "Processed prompts:  48%|████▊     | 239/500 [00:12<00:13, 18.70it/s, est. speed input: 2772.08 toks/s, output: 3382.09 toks/s]\n",
      "Processed prompts:  48%|████▊     | 242/500 [00:12<00:13, 19.00it/s, est. speed input: 2773.14 toks/s, output: 3385.49 toks/s]\n",
      "Processed prompts:  49%|████▉     | 247/500 [00:12<00:10, 23.92it/s, est. speed input: 2803.17 toks/s, output: 3443.50 toks/s]\n",
      "Processed prompts:  50%|█████     | 251/500 [00:12<00:10, 24.88it/s, est. speed input: 2816.50 toks/s, output: 3480.13 toks/s]\n",
      "Processed prompts:  51%|█████     | 254/500 [00:12<00:09, 25.11it/s, est. speed input: 2824.09 toks/s, output: 3494.51 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 258/500 [00:12<00:09, 25.81it/s, est. speed input: 2836.44 toks/s, output: 3527.90 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 261/500 [00:13<00:12, 19.64it/s, est. speed input: 2813.00 toks/s, output: 3505.28 toks/s]\n",
      "Processed prompts:  53%|█████▎    | 266/500 [00:13<00:10, 21.36it/s, est. speed input: 2823.86 toks/s, output: 3546.76 toks/s]\n",
      "Processed prompts:  54%|█████▍    | 269/500 [00:13<00:15, 14.70it/s, est. speed input: 2772.64 toks/s, output: 3474.85 toks/s]\n",
      "Processed prompts:  55%|█████▍    | 274/500 [00:14<00:13, 16.19it/s, est. speed input: 2772.50 toks/s, output: 3462.83 toks/s]\n",
      "Processed prompts:  56%|█████▌    | 279/500 [00:14<00:11, 19.17it/s, est. speed input: 2788.83 toks/s, output: 3483.57 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 283/500 [00:14<00:11, 18.78it/s, est. speed input: 2785.37 toks/s, output: 3484.65 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 286/500 [00:14<00:12, 17.81it/s, est. speed input: 2777.23 toks/s, output: 3487.85 toks/s]\n",
      "Processed prompts:  58%|█████▊    | 292/500 [00:14<00:10, 20.58it/s, est. speed input: 2793.04 toks/s, output: 3565.01 toks/s]\n",
      "Processed prompts:  59%|█████▉    | 295/500 [00:15<00:11, 18.50it/s, est. speed input: 2780.28 toks/s, output: 3569.11 toks/s]\n",
      "Processed prompts:  60%|█████▉    | 299/500 [00:15<00:09, 21.68it/s, est. speed input: 2798.33 toks/s, output: 3605.61 toks/s]\n",
      "Processed prompts:  60%|██████    | 302/500 [00:15<00:11, 17.54it/s, est. speed input: 2776.47 toks/s, output: 3584.93 toks/s]\n",
      "Processed prompts:  61%|██████    | 305/500 [00:15<00:10, 17.77it/s, est. speed input: 2774.84 toks/s, output: 3608.34 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 308/500 [00:15<00:09, 19.63it/s, est. speed input: 2782.93 toks/s, output: 3617.20 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 315/500 [00:15<00:06, 29.22it/s, est. speed input: 2827.00 toks/s, output: 3725.12 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 319/500 [00:16<00:07, 24.16it/s, est. speed input: 2820.25 toks/s, output: 3717.28 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 322/500 [00:16<00:10, 17.13it/s, est. speed input: 2787.04 toks/s, output: 3672.61 toks/s]\n",
      "Processed prompts:  65%|██████▌   | 325/500 [00:16<00:09, 18.96it/s, est. speed input: 2794.88 toks/s, output: 3695.28 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 328/500 [00:16<00:09, 18.79it/s, est. speed input: 2792.99 toks/s, output: 3724.06 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 331/500 [00:16<00:09, 18.00it/s, est. speed input: 2787.60 toks/s, output: 3742.01 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 334/500 [00:17<00:15, 10.56it/s, est. speed input: 2718.66 toks/s, output: 3656.32 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 336/500 [00:17<00:18,  8.78it/s, est. speed input: 2678.18 toks/s, output: 3633.96 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 341/500 [00:18<00:12, 12.72it/s, est. speed input: 2694.70 toks/s, output: 3698.27 toks/s]\n",
      "Processed prompts:  69%|██████▊   | 343/500 [00:18<00:16,  9.32it/s, est. speed input: 2644.87 toks/s, output: 3639.90 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 345/500 [00:19<00:33,  4.68it/s, est. speed input: 2499.89 toks/s, output: 3451.77 toks/s]\n",
      "Processed prompts:  70%|██████▉   | 348/500 [00:20<00:32,  4.71it/s, est. speed input: 2443.49 toks/s, output: 3396.75 toks/s]\n",
      "Processed prompts:  70%|██████▉   | 349/500 [00:20<00:30,  4.87it/s, est. speed input: 2431.56 toks/s, output: 3398.63 toks/s]\n",
      "Processed prompts:  70%|███████   | 350/500 [00:20<00:31,  4.78it/s, est. speed input: 2411.38 toks/s, output: 3378.24 toks/s]\n",
      "Processed prompts:  70%|███████   | 351/500 [00:21<00:42,  3.52it/s, est. speed input: 2348.55 toks/s, output: 3300.35 toks/s]\n",
      "Processed prompts:  70%|███████   | 352/500 [00:22<01:10,  2.09it/s, est. speed input: 2227.82 toks/s, output: 3155.42 toks/s]\n",
      "Processed prompts:  71%|███████   | 353/500 [00:22<01:05,  2.24it/s, est. speed input: 2200.99 toks/s, output: 3125.26 toks/s]\n",
      "Processed prompts:  71%|███████   | 354/500 [00:25<02:10,  1.12it/s, est. speed input: 2008.97 toks/s, output: 2865.06 toks/s]\n",
      "Processed prompts:  71%|███████   | 356/500 [00:25<01:26,  1.66it/s, est. speed input: 1990.09 toks/s, output: 2864.35 toks/s]\n",
      "Processed prompts:  72%|███████▏  | 358/500 [00:26<01:12,  1.96it/s, est. speed input: 1947.38 toks/s, output: 2827.67 toks/s]\n",
      "Processed prompts:  72%|███████▏  | 359/500 [00:26<01:12,  1.95it/s, est. speed input: 1914.61 toks/s, output: 2801.38 toks/s]\n",
      "Processed prompts:  72%|███████▏  | 360/500 [00:29<02:23,  1.02s/it, est. speed input: 1741.59 toks/s, output: 2576.05 toks/s]\n",
      "Processed prompts:  86%|████████▌ | 430/500 [00:29<00:03, 22.70it/s, est. speed input: 2074.06 toks/s, output: 4993.36 toks/s]\n",
      "Processed prompts:  90%|█████████ | 451/500 [00:32<00:03, 12.85it/s, est. speed input: 1953.41 toks/s, output: 5136.73 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 466/500 [00:34<00:02, 12.56it/s, est. speed input: 1942.52 toks/s, output: 5385.87 toks/s]\n",
      "Processed prompts:  95%|█████████▌| 477/500 [00:34<00:01, 13.02it/s, est. speed input: 1947.45 toks/s, output: 5598.01 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 485/500 [00:35<00:01, 12.24it/s, est. speed input: 1933.35 toks/s, output: 5694.23 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 491/500 [00:36<00:00, 11.26it/s, est. speed input: 1916.06 toks/s, output: 5742.36 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 496/500 [00:37<00:00,  8.53it/s, est. speed input: 1865.60 toks/s, output: 5669.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 500/500 [00:39<00:00, 12.59it/s, est. speed input: 1794.03 toks/s, output: 5511.91 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 2537.20it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:06<01:36,  1.61s/it, est. speed input: 89.91 toks/s, output: 91.92 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:08<00:51,  1.10it/s, est. speed input: 140.11 toks/s, output: 160.14 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:10<00:26,  1.81it/s, est. speed input: 209.13 toks/s, output: 280.96 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:11<00:13,  2.90it/s, est. speed input: 289.26 toks/s, output: 431.85 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:16<00:19,  1.84it/s, est. speed input: 244.02 toks/s, output: 412.60 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:17<00:14,  2.21it/s, est. speed input: 266.02 toks/s, output: 517.79 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:19<00:14,  1.92it/s, est. speed input: 257.60 toks/s, output: 540.20 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:22<00:12,  1.88it/s, est. speed input: 256.94 toks/s, output: 581.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:22<00:00,  2.84it/s, est. speed input: 402.54 toks/s, output: 1076.27 toks/s]\n",
      "Adding requests:   0%|          | 0/500 [00:00<?, ?it/s]\n",
      "Adding requests: 100%|██████████| 500/500 [00:00<00:00, 10306.33it/s]\n",
      "Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   0%|          | 1/500 [00:02<19:58,  2.40s/it, est. speed input: 60.39 toks/s, output: 33.32 toks/s]\n",
      "Processed prompts:   1%|          | 3/500 [00:02<05:30,  1.51it/s, est. speed input: 171.45 toks/s, output: 98.25 toks/s]\n",
      "Processed prompts:   1%|          | 5/500 [00:02<03:19,  2.48it/s, est. speed input: 251.98 toks/s, output: 154.08 toks/s]\n",
      "Processed prompts:   2%|▏         | 9/500 [00:02<01:30,  5.41it/s, est. speed input: 429.38 toks/s, output: 277.28 toks/s]\n",
      "Processed prompts:   2%|▏         | 11/500 [00:03<01:15,  6.45it/s, est. speed input: 495.47 toks/s, output: 328.40 toks/s]\n",
      "Processed prompts:   3%|▎         | 15/500 [00:03<00:46, 10.34it/s, est. speed input: 651.01 toks/s, output: 450.39 toks/s]\n",
      "Processed prompts:   4%|▍         | 20/500 [00:03<00:30, 15.78it/s, est. speed input: 841.78 toks/s, output: 601.95 toks/s]\n",
      "Processed prompts:   5%|▌         | 26/500 [00:03<00:21, 21.74it/s, est. speed input: 1049.23 toks/s, output: 776.31 toks/s]\n",
      "Processed prompts:   6%|▌         | 31/500 [00:03<00:17, 26.32it/s, est. speed input: 1211.98 toks/s, output: 919.12 toks/s]\n",
      "Processed prompts:   8%|▊         | 38/500 [00:03<00:14, 32.53it/s, est. speed input: 1431.22 toks/s, output: 1117.44 toks/s]\n",
      "Processed prompts:   9%|▊         | 43/500 [00:03<00:13, 33.32it/s, est. speed input: 1561.52 toks/s, output: 1243.73 toks/s]\n",
      "Processed prompts:  10%|▉         | 48/500 [00:04<00:12, 36.07it/s, est. speed input: 1696.51 toks/s, output: 1378.56 toks/s]\n",
      "Processed prompts:  11%|█         | 53/500 [00:04<00:11, 38.10it/s, est. speed input: 1821.02 toks/s, output: 1508.66 toks/s]\n",
      "Processed prompts:  12%|█▏        | 59/500 [00:04<00:10, 42.36it/s, est. speed input: 1975.40 toks/s, output: 1672.61 toks/s]\n",
      "Processed prompts:  14%|█▎        | 68/500 [00:04<00:08, 52.28it/s, est. speed input: 2217.13 toks/s, output: 1931.15 toks/s]\n",
      "Processed prompts:  15%|█▍        | 74/500 [00:04<00:09, 43.55it/s, est. speed input: 2307.38 toks/s, output: 2049.70 toks/s]\n",
      "Processed prompts:  16%|█▌        | 79/500 [00:04<00:09, 43.78it/s, est. speed input: 2404.38 toks/s, output: 2170.50 toks/s]\n",
      "Processed prompts:  17%|█▋        | 84/500 [00:04<00:09, 43.91it/s, est. speed input: 2495.75 toks/s, output: 2288.95 toks/s]\n",
      "Processed prompts:  18%|█▊        | 89/500 [00:04<00:11, 36.56it/s, est. speed input: 2539.81 toks/s, output: 2367.74 toks/s]\n",
      "Processed prompts:  19%|█▊        | 93/500 [00:05<00:11, 34.08it/s, est. speed input: 2580.18 toks/s, output: 2438.11 toks/s]\n",
      "Processed prompts:  19%|█▉        | 97/500 [00:05<00:11, 34.20it/s, est. speed input: 2632.03 toks/s, output: 2520.24 toks/s]\n",
      "Processed prompts:  20%|██        | 101/500 [00:05<00:13, 28.59it/s, est. speed input: 2638.78 toks/s, output: 2561.70 toks/s]\n",
      "Processed prompts:  21%|██        | 105/500 [00:05<00:13, 30.26it/s, est. speed input: 2688.65 toks/s, output: 2647.01 toks/s]\n",
      "Processed prompts:  22%|██▏       | 110/500 [00:05<00:12, 31.56it/s, est. speed input: 2745.63 toks/s, output: 2749.66 toks/s]\n",
      "Processed prompts:  23%|██▎       | 114/500 [00:05<00:15, 24.72it/s, est. speed input: 2723.25 toks/s, output: 2752.64 toks/s]\n",
      "Processed prompts:  24%|██▎       | 118/500 [00:06<00:14, 25.64it/s, est. speed input: 2755.09 toks/s, output: 2825.04 toks/s]\n",
      "Processed prompts:  24%|██▍       | 122/500 [00:06<00:15, 23.79it/s, est. speed input: 2759.62 toks/s, output: 2852.02 toks/s]\n",
      "Processed prompts:  25%|██▌       | 127/500 [00:06<00:14, 25.42it/s, est. speed input: 2797.88 toks/s, output: 2913.09 toks/s]\n",
      "Processed prompts:  26%|██▋       | 132/500 [00:06<00:13, 27.92it/s, est. speed input: 2844.94 toks/s, output: 3021.14 toks/s]\n",
      "Processed prompts:  27%|██▋       | 135/500 [00:06<00:16, 22.27it/s, est. speed input: 2811.39 toks/s, output: 3006.18 toks/s]\n",
      "Processed prompts:  28%|██▊       | 138/500 [00:06<00:15, 23.06it/s, est. speed input: 2826.48 toks/s, output: 3031.29 toks/s]\n",
      "Processed prompts:  29%|██▉       | 145/500 [00:07<00:11, 31.65it/s, est. speed input: 2921.83 toks/s, output: 3170.66 toks/s]\n",
      "Processed prompts:  30%|██▉       | 149/500 [00:07<00:11, 30.54it/s, est. speed input: 2941.65 toks/s, output: 3184.83 toks/s]\n",
      "Processed prompts:  31%|███       | 153/500 [00:07<00:11, 29.68it/s, est. speed input: 2961.24 toks/s, output: 3203.04 toks/s]\n",
      "Processed prompts:  31%|███▏      | 157/500 [00:07<00:15, 22.48it/s, est. speed input: 2923.85 toks/s, output: 3155.60 toks/s]\n",
      "Processed prompts:  32%|███▏      | 160/500 [00:07<00:16, 20.98it/s, est. speed input: 2913.78 toks/s, output: 3148.30 toks/s]\n",
      "Processed prompts:  33%|███▎      | 164/500 [00:07<00:14, 23.76it/s, est. speed input: 2942.61 toks/s, output: 3225.44 toks/s]\n",
      "Processed prompts:  34%|███▍      | 171/500 [00:08<00:10, 30.34it/s, est. speed input: 3010.90 toks/s, output: 3288.70 toks/s]\n",
      "Processed prompts:  35%|███▌      | 175/500 [00:08<00:11, 28.10it/s, est. speed input: 3016.84 toks/s, output: 3298.91 toks/s]\n",
      "Processed prompts:  36%|███▌      | 180/500 [00:08<00:10, 31.56it/s, est. speed input: 3059.48 toks/s, output: 3379.68 toks/s]\n",
      "Processed prompts:  37%|███▋      | 184/500 [00:08<00:09, 32.26it/s, est. speed input: 3084.09 toks/s, output: 3426.04 toks/s]\n",
      "Processed prompts:  38%|███▊      | 188/500 [00:08<00:10, 30.85it/s, est. speed input: 3098.61 toks/s, output: 3454.66 toks/s]\n",
      "Processed prompts:  39%|███▊      | 193/500 [00:08<00:09, 34.09it/s, est. speed input: 3138.88 toks/s, output: 3502.58 toks/s]\n",
      "Processed prompts:  39%|███▉      | 197/500 [00:09<00:12, 24.31it/s, est. speed input: 3100.97 toks/s, output: 3493.62 toks/s]\n",
      "Processed prompts:  40%|████      | 201/500 [00:09<00:11, 25.09it/s, est. speed input: 3114.22 toks/s, output: 3504.10 toks/s]\n",
      "Processed prompts:  41%|████      | 206/500 [00:09<00:11, 26.08it/s, est. speed input: 3131.37 toks/s, output: 3577.99 toks/s]\n",
      "Processed prompts:  42%|████▏     | 209/500 [00:09<00:11, 26.00it/s, est. speed input: 3137.87 toks/s, output: 3579.85 toks/s]\n",
      "Processed prompts:  42%|████▏     | 212/500 [00:09<00:12, 23.13it/s, est. speed input: 3125.65 toks/s, output: 3608.33 toks/s]\n",
      "Processed prompts:  43%|████▎     | 216/500 [00:09<00:12, 22.86it/s, est. speed input: 3126.71 toks/s, output: 3630.69 toks/s]\n",
      "Processed prompts:  44%|████▍     | 219/500 [00:10<00:13, 20.12it/s, est. speed input: 3106.62 toks/s, output: 3628.07 toks/s]\n",
      "Processed prompts:  44%|████▍     | 222/500 [00:10<00:14, 19.25it/s, est. speed input: 3095.77 toks/s, output: 3649.45 toks/s]\n",
      "Processed prompts:  45%|████▌     | 227/500 [00:10<00:11, 24.37it/s, est. speed input: 3128.70 toks/s, output: 3741.98 toks/s]\n",
      "Processed prompts:  47%|████▋     | 233/500 [00:10<00:09, 27.57it/s, est. speed input: 3158.10 toks/s, output: 3797.18 toks/s]\n",
      "Processed prompts:  47%|████▋     | 236/500 [00:10<00:13, 19.29it/s, est. speed input: 3104.16 toks/s, output: 3753.20 toks/s]\n",
      "Processed prompts:  48%|████▊     | 239/500 [00:11<00:16, 15.36it/s, est. speed input: 3053.41 toks/s, output: 3692.09 toks/s]\n",
      "Processed prompts:  48%|████▊     | 242/500 [00:11<00:15, 16.36it/s, est. speed input: 3051.36 toks/s, output: 3717.68 toks/s]\n",
      "Processed prompts:  49%|████▉     | 247/500 [00:11<00:14, 17.24it/s, est. speed input: 3042.86 toks/s, output: 3723.63 toks/s]\n",
      "Processed prompts:  50%|████▉     | 249/500 [00:11<00:14, 17.16it/s, est. speed input: 3036.59 toks/s, output: 3710.59 toks/s]\n",
      "Processed prompts:  50%|█████     | 252/500 [00:11<00:15, 15.77it/s, est. speed input: 3013.89 toks/s, output: 3702.37 toks/s]\n",
      "Processed prompts:  51%|█████     | 254/500 [00:12<00:18, 13.48it/s, est. speed input: 2980.07 toks/s, output: 3662.15 toks/s]\n",
      "Processed prompts:  51%|█████▏    | 257/500 [00:12<00:16, 15.16it/s, est. speed input: 2980.07 toks/s, output: 3652.94 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 259/500 [00:12<00:16, 14.89it/s, est. speed input: 2968.51 toks/s, output: 3648.31 toks/s]\n",
      "Processed prompts:  53%|█████▎    | 265/500 [00:12<00:10, 23.02it/s, est. speed input: 3009.75 toks/s, output: 3713.99 toks/s]\n",
      "Processed prompts:  54%|█████▎    | 268/500 [00:12<00:11, 20.31it/s, est. speed input: 2997.30 toks/s, output: 3693.85 toks/s]\n",
      "Processed prompts:  54%|█████▍    | 271/500 [00:12<00:11, 19.53it/s, est. speed input: 2991.22 toks/s, output: 3689.55 toks/s]\n",
      "Processed prompts:  55%|█████▍    | 274/500 [00:13<00:11, 20.01it/s, est. speed input: 2991.41 toks/s, output: 3681.30 toks/s]\n",
      "Processed prompts:  56%|█████▌    | 278/500 [00:13<00:09, 22.34it/s, est. speed input: 3003.29 toks/s, output: 3729.11 toks/s]\n",
      "Processed prompts:  56%|█████▌    | 281/500 [00:13<00:09, 22.15it/s, est. speed input: 3004.10 toks/s, output: 3731.60 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 285/500 [00:13<00:10, 19.60it/s, est. speed input: 2990.48 toks/s, output: 3719.25 toks/s]\n",
      "Processed prompts:  58%|█████▊    | 288/500 [00:13<00:11, 18.34it/s, est. speed input: 2979.59 toks/s, output: 3722.83 toks/s]\n",
      "Processed prompts:  58%|█████▊    | 290/500 [00:13<00:13, 15.21it/s, est. speed input: 2953.54 toks/s, output: 3699.76 toks/s]\n",
      "Processed prompts:  59%|█████▉    | 295/500 [00:14<00:11, 17.75it/s, est. speed input: 2958.74 toks/s, output: 3718.21 toks/s]\n",
      "Processed prompts:  59%|█████▉    | 297/500 [00:14<00:13, 15.58it/s, est. speed input: 2938.38 toks/s, output: 3699.51 toks/s]\n",
      "Processed prompts:  60%|█████▉    | 299/500 [00:14<00:12, 16.09it/s, est. speed input: 2935.92 toks/s, output: 3701.51 toks/s]\n",
      "Processed prompts:  60%|██████    | 302/500 [00:14<00:11, 16.76it/s, est. speed input: 2932.43 toks/s, output: 3699.21 toks/s]\n",
      "Processed prompts:  61%|██████    | 304/500 [00:14<00:14, 13.41it/s, est. speed input: 2902.78 toks/s, output: 3667.27 toks/s]\n",
      "Processed prompts:  61%|██████▏   | 307/500 [00:15<00:11, 16.18it/s, est. speed input: 2910.76 toks/s, output: 3690.19 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 309/500 [00:15<00:11, 16.70it/s, est. speed input: 2908.80 toks/s, output: 3689.21 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 311/500 [00:15<00:12, 15.31it/s, est. speed input: 2896.37 toks/s, output: 3679.88 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 313/500 [00:15<00:14, 12.48it/s, est. speed input: 2869.79 toks/s, output: 3643.77 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 315/500 [00:15<00:18, 10.15it/s, est. speed input: 2834.56 toks/s, output: 3622.81 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 317/500 [00:16<00:19,  9.26it/s, est. speed input: 2806.14 toks/s, output: 3599.69 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 319/500 [00:16<00:29,  6.07it/s, est. speed input: 2720.84 toks/s, output: 3495.83 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 321/500 [00:16<00:24,  7.35it/s, est. speed input: 2716.55 toks/s, output: 3501.84 toks/s]\n",
      "Processed prompts:  65%|██████▍   | 323/500 [00:17<00:27,  6.43it/s, est. speed input: 2668.97 toks/s, output: 3460.00 toks/s]\n",
      "Processed prompts:  65%|██████▌   | 325/500 [00:17<00:22,  7.75it/s, est. speed input: 2665.33 toks/s, output: 3475.69 toks/s]\n",
      "Processed prompts:  65%|██████▌   | 327/500 [00:17<00:20,  8.46it/s, est. speed input: 2653.61 toks/s, output: 3491.86 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 329/500 [00:17<00:20,  8.20it/s, est. speed input: 2630.81 toks/s, output: 3477.17 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 330/500 [00:17<00:21,  8.06it/s, est. speed input: 2619.28 toks/s, output: 3472.31 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 331/500 [00:18<00:29,  5.75it/s, est. speed input: 2573.65 toks/s, output: 3429.26 toks/s]\n",
      "Processed prompts:  66%|██████▋   | 332/500 [00:18<00:32,  5.18it/s, est. speed input: 2545.14 toks/s, output: 3401.55 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 333/500 [00:18<00:32,  5.08it/s, est. speed input: 2524.56 toks/s, output: 3399.14 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 334/500 [00:18<00:28,  5.78it/s, est. speed input: 2518.14 toks/s, output: 3398.77 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 335/500 [00:19<00:46,  3.58it/s, est. speed input: 2451.72 toks/s, output: 3334.52 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 337/500 [00:19<00:40,  4.03it/s, est. speed input: 2415.09 toks/s, output: 3301.63 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 338/500 [00:19<00:34,  4.68it/s, est. speed input: 2409.61 toks/s, output: 3302.36 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 340/500 [00:20<00:23,  6.73it/s, est. speed input: 2411.31 toks/s, output: 3323.34 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 342/500 [00:20<00:27,  5.70it/s, est. speed input: 2372.92 toks/s, output: 3322.32 toks/s]\n",
      "Processed prompts:  69%|██████▊   | 343/500 [00:21<00:44,  3.56it/s, est. speed input: 2303.10 toks/s, output: 3250.68 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 344/500 [00:21<00:51,  3.03it/s, est. speed input: 2257.02 toks/s, output: 3203.89 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 345/500 [00:22<00:52,  2.95it/s, est. speed input: 2225.96 toks/s, output: 3171.39 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 346/500 [00:22<00:43,  3.51it/s, est. speed input: 2219.25 toks/s, output: 3171.06 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 347/500 [00:22<00:45,  3.34it/s, est. speed input: 2192.36 toks/s, output: 3142.74 toks/s]\n",
      "Processed prompts:  70%|██████▉   | 348/500 [00:23<01:16,  1.97it/s, est. speed input: 2101.74 toks/s, output: 3039.96 toks/s]\n",
      "Processed prompts:  70%|██████▉   | 349/500 [00:26<03:08,  1.25s/it, est. speed input: 1861.55 toks/s, output: 2708.21 toks/s]\n",
      "Processed prompts:  70%|███████   | 350/500 [00:26<02:20,  1.07it/s, est. speed input: 1856.33 toks/s, output: 2715.70 toks/s]\n",
      "Processed prompts:  70%|███████   | 351/500 [00:28<02:34,  1.04s/it, est. speed input: 1775.93 toks/s, output: 2627.12 toks/s]\n",
      "Processed prompts:  86%|████████▌ | 430/500 [00:30<00:04, 17.33it/s, est. speed input: 2017.90 toks/s, output: 5099.83 toks/s]\n",
      "Processed prompts:  86%|████████▋ | 432/500 [00:30<00:04, 15.62it/s, est. speed input: 1995.50 toks/s, output: 5085.85 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 434/500 [00:31<00:04, 15.31it/s, est. speed input: 1992.81 toks/s, output: 5121.49 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 439/500 [00:31<00:03, 16.65it/s, est. speed input: 2006.49 toks/s, output: 5262.51 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 441/500 [00:31<00:03, 16.01it/s, est. speed input: 2003.79 toks/s, output: 5296.89 toks/s]\n",
      "Processed prompts:  89%|████████▊ | 443/500 [00:31<00:03, 15.83it/s, est. speed input: 2003.93 toks/s, output: 5338.52 toks/s]\n",
      "Processed prompts:  90%|████████▉ | 449/500 [00:31<00:02, 19.89it/s, est. speed input: 2023.66 toks/s, output: 5513.37 toks/s]\n",
      "Processed prompts:  90%|█████████ | 452/500 [00:31<00:02, 17.84it/s, est. speed input: 2021.18 toks/s, output: 5566.40 toks/s]\n",
      "Processed prompts:  91%|█████████ | 455/500 [00:32<00:03, 14.19it/s, est. speed input: 2010.04 toks/s, output: 5594.93 toks/s]\n",
      "Processed prompts:  91%|█████████▏| 457/500 [00:32<00:03, 12.11it/s, est. speed input: 2000.66 toks/s, output: 5607.46 toks/s]\n",
      "Processed prompts:  92%|█████████▏| 461/500 [00:32<00:02, 14.48it/s, est. speed input: 2008.61 toks/s, output: 5705.69 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 463/500 [00:32<00:02, 12.63it/s, est. speed input: 2002.22 toks/s, output: 5724.71 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 465/500 [00:33<00:03, 11.34it/s, est. speed input: 1995.89 toks/s, output: 5744.10 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 467/500 [00:33<00:03, 10.40it/s, est. speed input: 1989.82 toks/s, output: 5762.99 toks/s]\n",
      "Processed prompts:  94%|█████████▍| 469/500 [00:33<00:03,  9.75it/s, est. speed input: 1983.86 toks/s, output: 5782.02 toks/s]\n",
      "Processed prompts:  94%|█████████▍| 472/500 [00:33<00:02, 12.51it/s, est. speed input: 1990.03 toks/s, output: 5853.89 toks/s]\n",
      "Processed prompts:  95%|█████████▌| 475/500 [00:34<00:02, 11.40it/s, est. speed input: 1984.42 toks/s, output: 5890.70 toks/s]\n",
      "Processed prompts:  95%|█████████▌| 477/500 [00:34<00:02, 10.17it/s, est. speed input: 1977.32 toks/s, output: 5904.93 toks/s]\n",
      "Processed prompts:  96%|█████████▌| 480/500 [00:34<00:01, 11.69it/s, est. speed input: 1979.37 toks/s, output: 5962.79 toks/s]\n",
      "Processed prompts:  96%|█████████▋| 482/500 [00:34<00:01, 12.80it/s, est. speed input: 1981.33 toks/s, output: 6002.90 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 484/500 [00:34<00:01, 13.88it/s, est. speed input: 1983.39 toks/s, output: 6042.94 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 487/500 [00:35<00:01,  9.49it/s, est. speed input: 1967.62 toks/s, output: 6044.87 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 490/500 [00:35<00:00, 11.85it/s, est. speed input: 1972.46 toks/s, output: 6109.62 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 492/500 [00:35<00:00, 10.53it/s, est. speed input: 1966.43 toks/s, output: 6123.25 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 494/500 [00:35<00:00,  9.92it/s, est. speed input: 1961.46 toks/s, output: 6140.12 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 496/500 [00:36<00:00, 10.35it/s, est. speed input: 1960.13 toks/s, output: 6167.93 toks/s]\n",
      "Processed prompts: 100%|█████████▉| 498/500 [00:36<00:00,  5.79it/s, est. speed input: 1928.38 toks/s, output: 6099.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 500/500 [00:36<00:00, 13.55it/s, est. speed input: 1930.58 toks/s, output: 6137.38 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 2517.87it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:04<01:09,  1.15s/it, est. speed input: 125.73 toks/s, output: 121.40 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:04<00:28,  2.00it/s, est. speed input: 238.76 toks/s, output: 239.80 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:07<00:29,  1.77it/s, est. speed input: 232.11 toks/s, output: 271.74 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:07<00:18,  2.63it/s, est. speed input: 293.23 toks/s, output: 336.54 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:10<00:20,  2.16it/s, est. speed input: 278.44 toks/s, output: 358.77 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:10<00:14,  2.82it/s, est. speed input: 315.94 toks/s, output: 435.01 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:10<00:09,  3.93it/s, est. speed input: 362.93 toks/s, output: 534.79 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:11<00:05,  5.45it/s, est. speed input: 411.16 toks/s, output: 615.38 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:12<00:07,  3.89it/s, est. speed input: 402.67 toks/s, output: 629.50 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:13<00:05,  4.31it/s, est. speed input: 424.64 toks/s, output: 689.66 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 44/64 [00:15<00:06,  3.09it/s, est. speed input: 403.99 toks/s, output: 684.26 toks/s]\n",
      "Processed prompts:  75%|███████▌  | 48/64 [00:17<00:06,  2.55it/s, est. speed input: 386.83 toks/s, output: 666.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:22<00:00,  2.86it/s, est. speed input: 408.79 toks/s, output: 919.29 toks/s]\n",
      "Adding requests:   0%|          | 0/500 [00:00<?, ?it/s]\n",
      "Adding requests: 100%|██████████| 500/500 [00:00<00:00, 9823.28it/s]\n",
      "Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   0%|          | 1/500 [00:02<20:25,  2.46s/it, est. speed input: 57.43 toks/s, output: 32.99 toks/s]\n",
      "Processed prompts:   1%|          | 3/500 [00:02<05:47,  1.43it/s, est. speed input: 162.63 toks/s, output: 95.21 toks/s]\n",
      "Processed prompts:   1%|          | 5/500 [00:02<03:06,  2.66it/s, est. speed input: 256.38 toks/s, output: 155.49 toks/s]\n",
      "Processed prompts:   1%|▏         | 7/500 [00:02<01:58,  4.16it/s, est. speed input: 344.34 toks/s, output: 215.08 toks/s]\n",
      "Processed prompts:   2%|▏         | 9/500 [00:02<01:24,  5.82it/s, est. speed input: 425.19 toks/s, output: 273.22 toks/s]\n",
      "Processed prompts:   3%|▎         | 15/500 [00:03<00:38, 12.45it/s, est. speed input: 673.41 toks/s, output: 454.99 toks/s]\n",
      "Processed prompts:   4%|▍         | 21/500 [00:03<00:24, 19.34it/s, est. speed input: 908.97 toks/s, output: 638.37 toks/s]\n",
      "Processed prompts:   5%|▌         | 27/500 [00:03<00:20, 22.57it/s, est. speed input: 1101.22 toks/s, output: 793.82 toks/s]\n",
      "Processed prompts:   6%|▌         | 31/500 [00:03<00:21, 21.83it/s, est. speed input: 1195.67 toks/s, output: 882.30 toks/s]\n",
      "Processed prompts:   7%|▋         | 37/500 [00:03<00:17, 26.56it/s, est. speed input: 1374.05 toks/s, output: 1046.94 toks/s]\n",
      "Processed prompts:   8%|▊         | 42/500 [00:03<00:15, 30.27it/s, est. speed input: 1514.49 toks/s, output: 1183.79 toks/s]\n",
      "Processed prompts:   9%|▉         | 46/500 [00:04<00:14, 31.43it/s, est. speed input: 1613.58 toks/s, output: 1284.99 toks/s]\n",
      "Processed prompts:  10%|█         | 51/500 [00:04<00:12, 34.69it/s, est. speed input: 1744.87 toks/s, output: 1416.94 toks/s]\n",
      "Processed prompts:  11%|█▏        | 57/500 [00:04<00:12, 34.84it/s, est. speed input: 1873.37 toks/s, output: 1559.86 toks/s]\n",
      "Processed prompts:  12%|█▏        | 61/500 [00:04<00:12, 34.95it/s, est. speed input: 1955.20 toks/s, output: 1654.27 toks/s]\n",
      "Processed prompts:  13%|█▎        | 67/500 [00:04<00:10, 39.68it/s, est. speed input: 2094.01 toks/s, output: 1814.29 toks/s]\n",
      "Processed prompts:  15%|█▍        | 73/500 [00:04<00:10, 40.66it/s, est. speed input: 2215.28 toks/s, output: 1960.23 toks/s]\n",
      "Processed prompts:  16%|█▌        | 78/500 [00:04<00:10, 41.67it/s, est. speed input: 2312.67 toks/s, output: 2082.65 toks/s]\n",
      "Processed prompts:  17%|█▋        | 83/500 [00:04<00:09, 42.30it/s, est. speed input: 2402.53 toks/s, output: 2202.57 toks/s]\n",
      "Processed prompts:  18%|█▊        | 88/500 [00:05<00:12, 33.18it/s, est. speed input: 2435.84 toks/s, output: 2270.38 toks/s]\n",
      "Processed prompts:  19%|█▉        | 94/500 [00:05<00:11, 35.49it/s, est. speed input: 2530.99 toks/s, output: 2408.81 toks/s]\n",
      "Processed prompts:  20%|█▉        | 98/500 [00:05<00:12, 33.44it/s, est. speed input: 2569.62 toks/s, output: 2480.37 toks/s]\n",
      "Processed prompts:  20%|██        | 102/500 [00:05<00:14, 28.42it/s, est. speed input: 2577.03 toks/s, output: 2526.80 toks/s]\n",
      "Processed prompts:  21%|██        | 106/500 [00:05<00:16, 24.32it/s, est. speed input: 2574.29 toks/s, output: 2563.33 toks/s]\n",
      "Processed prompts:  22%|██▏       | 111/500 [00:05<00:14, 26.86it/s, est. speed input: 2630.46 toks/s, output: 2670.02 toks/s]\n",
      "Processed prompts:  23%|██▎       | 114/500 [00:06<00:16, 23.98it/s, est. speed input: 2626.00 toks/s, output: 2696.90 toks/s]\n",
      "Processed prompts:  23%|██▎       | 117/500 [00:06<00:17, 22.02it/s, est. speed input: 2623.34 toks/s, output: 2726.10 toks/s]\n",
      "Processed prompts:  24%|██▍       | 120/500 [00:06<00:20, 18.77it/s, est. speed input: 2596.97 toks/s, output: 2732.54 toks/s]\n",
      "Processed prompts:  25%|██▍       | 124/500 [00:06<00:17, 21.96it/s, est. speed input: 2636.59 toks/s, output: 2789.07 toks/s]\n",
      "Processed prompts:  26%|██▌       | 129/500 [00:06<00:16, 23.00it/s, est. speed input: 2662.95 toks/s, output: 2840.21 toks/s]\n",
      "Processed prompts:  26%|██▋       | 132/500 [00:07<00:18, 19.44it/s, est. speed input: 2637.22 toks/s, output: 2810.42 toks/s]\n",
      "Processed prompts:  27%|██▋       | 135/500 [00:07<00:18, 19.81it/s, est. speed input: 2644.40 toks/s, output: 2823.57 toks/s]\n",
      "Processed prompts:  28%|██▊       | 138/500 [00:07<00:21, 16.64it/s, est. speed input: 2609.99 toks/s, output: 2814.64 toks/s]\n",
      "Processed prompts:  28%|██▊       | 141/500 [00:07<00:20, 17.64it/s, est. speed input: 2617.84 toks/s, output: 2842.30 toks/s]\n",
      "Processed prompts:  29%|██▊       | 143/500 [00:07<00:20, 17.60it/s, est. speed input: 2616.38 toks/s, output: 2852.70 toks/s]\n",
      "Processed prompts:  29%|██▉       | 147/500 [00:07<00:16, 21.55it/s, est. speed input: 2650.43 toks/s, output: 2886.08 toks/s]\n",
      "Processed prompts:  30%|███       | 152/500 [00:08<00:12, 26.93it/s, est. speed input: 2701.36 toks/s, output: 2955.96 toks/s]\n",
      "Processed prompts:  31%|███       | 156/500 [00:08<00:11, 28.83it/s, est. speed input: 2733.61 toks/s, output: 2995.00 toks/s]\n",
      "Processed prompts:  32%|███▏      | 160/500 [00:08<00:11, 30.11it/s, est. speed input: 2763.09 toks/s, output: 3040.10 toks/s]\n",
      "Processed prompts:  33%|███▎      | 164/500 [00:08<00:10, 31.23it/s, est. speed input: 2792.00 toks/s, output: 3105.19 toks/s]\n",
      "Processed prompts:  34%|███▍      | 169/500 [00:08<00:10, 30.26it/s, est. speed input: 2817.98 toks/s, output: 3173.17 toks/s]\n",
      "Processed prompts:  35%|███▍      | 173/500 [00:08<00:10, 31.13it/s, est. speed input: 2845.10 toks/s, output: 3225.78 toks/s]\n",
      "Processed prompts:  35%|███▌      | 177/500 [00:08<00:14, 21.61it/s, est. speed input: 2805.74 toks/s, output: 3198.91 toks/s]\n",
      "Processed prompts:  36%|███▌      | 180/500 [00:09<00:15, 20.34it/s, est. speed input: 2798.40 toks/s, output: 3206.00 toks/s]\n",
      "Processed prompts:  37%|███▋      | 185/500 [00:09<00:12, 25.12it/s, est. speed input: 2840.08 toks/s, output: 3298.24 toks/s]\n",
      "Processed prompts:  38%|███▊      | 191/500 [00:09<00:11, 27.92it/s, est. speed input: 2877.29 toks/s, output: 3385.46 toks/s]\n",
      "Processed prompts:  39%|███▉      | 195/500 [00:09<00:10, 27.79it/s, est. speed input: 2892.71 toks/s, output: 3413.39 toks/s]\n",
      "Processed prompts:  40%|████      | 200/500 [00:09<00:09, 31.17it/s, est. speed input: 2930.61 toks/s, output: 3491.43 toks/s]\n",
      "Processed prompts:  41%|████      | 204/500 [00:09<00:09, 31.83it/s, est. speed input: 2953.18 toks/s, output: 3513.76 toks/s]\n",
      "Processed prompts:  42%|████▏     | 208/500 [00:09<00:09, 30.25it/s, est. speed input: 2966.82 toks/s, output: 3549.98 toks/s]\n",
      "Processed prompts:  42%|████▏     | 212/500 [00:10<00:12, 22.41it/s, est. speed input: 2937.26 toks/s, output: 3546.21 toks/s]\n",
      "Processed prompts:  43%|████▎     | 215/500 [00:10<00:12, 23.09it/s, est. speed input: 2945.43 toks/s, output: 3547.72 toks/s]\n",
      "Processed prompts:  44%|████▍     | 219/500 [00:10<00:10, 25.58it/s, est. speed input: 2965.90 toks/s, output: 3590.52 toks/s]\n",
      "Processed prompts:  45%|████▍     | 223/500 [00:10<00:10, 27.66it/s, est. speed input: 2986.16 toks/s, output: 3634.16 toks/s]\n",
      "Processed prompts:  45%|████▌     | 226/500 [00:10<00:10, 25.41it/s, est. speed input: 2984.39 toks/s, output: 3627.23 toks/s]\n",
      "Processed prompts:  46%|████▌     | 229/500 [00:11<00:13, 19.99it/s, est. speed input: 2957.53 toks/s, output: 3609.47 toks/s]\n",
      "Processed prompts:  46%|████▋     | 232/500 [00:11<00:16, 15.88it/s, est. speed input: 2918.32 toks/s, output: 3586.42 toks/s]\n",
      "Processed prompts:  47%|████▋     | 234/500 [00:11<00:17, 15.38it/s, est. speed input: 2906.06 toks/s, output: 3579.02 toks/s]\n",
      "Processed prompts:  48%|████▊     | 238/500 [00:11<00:13, 19.24it/s, est. speed input: 2925.08 toks/s, output: 3627.07 toks/s]\n",
      "Processed prompts:  48%|████▊     | 241/500 [00:11<00:13, 19.44it/s, est. speed input: 2924.61 toks/s, output: 3648.06 toks/s]\n",
      "Processed prompts:  49%|████▉     | 244/500 [00:11<00:14, 17.62it/s, est. speed input: 2908.89 toks/s, output: 3627.93 toks/s]\n",
      "Processed prompts:  49%|████▉     | 247/500 [00:12<00:13, 18.44it/s, est. speed input: 2910.06 toks/s, output: 3629.79 toks/s]\n",
      "Processed prompts:  50%|████▉     | 249/500 [00:12<00:13, 18.17it/s, est. speed input: 2905.44 toks/s, output: 3639.40 toks/s]\n",
      "Processed prompts:  51%|█████     | 254/500 [00:12<00:10, 22.89it/s, est. speed input: 2929.24 toks/s, output: 3675.95 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 259/500 [00:12<00:09, 26.36it/s, est. speed input: 2952.50 toks/s, output: 3712.97 toks/s]\n",
      "Processed prompts:  53%|█████▎    | 263/500 [00:12<00:08, 28.51it/s, est. speed input: 2971.11 toks/s, output: 3761.52 toks/s]\n",
      "Processed prompts:  54%|█████▎    | 268/500 [00:12<00:07, 32.48it/s, est. speed input: 3000.35 toks/s, output: 3794.33 toks/s]\n",
      "Processed prompts:  54%|█████▍    | 272/500 [00:13<00:12, 18.46it/s, est. speed input: 2941.14 toks/s, output: 3754.50 toks/s]\n",
      "Processed prompts:  55%|█████▌    | 275/500 [00:13<00:11, 19.04it/s, est. speed input: 2942.24 toks/s, output: 3805.21 toks/s]\n",
      "Processed prompts:  56%|█████▌    | 279/500 [00:13<00:14, 15.45it/s, est. speed input: 2904.78 toks/s, output: 3774.82 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 282/500 [00:13<00:12, 17.25it/s, est. speed input: 2911.73 toks/s, output: 3786.05 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 285/500 [00:14<00:14, 14.92it/s, est. speed input: 2884.31 toks/s, output: 3746.35 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 287/500 [00:14<00:16, 13.23it/s, est. speed input: 2860.19 toks/s, output: 3714.08 toks/s]\n",
      "Processed prompts:  58%|█████▊    | 289/500 [00:14<00:14, 14.08it/s, est. speed input: 2857.89 toks/s, output: 3712.42 toks/s]\n",
      "Processed prompts:  59%|█████▊    | 293/500 [00:14<00:11, 18.47it/s, est. speed input: 2875.36 toks/s, output: 3748.83 toks/s]\n",
      "Processed prompts:  59%|█████▉    | 296/500 [00:14<00:10, 20.39it/s, est. speed input: 2883.14 toks/s, output: 3770.21 toks/s]\n",
      "Processed prompts:  60%|█████▉    | 299/500 [00:14<00:14, 13.87it/s, est. speed input: 2838.61 toks/s, output: 3734.34 toks/s]\n",
      "Processed prompts:  60%|██████    | 301/500 [00:15<00:13, 14.67it/s, est. speed input: 2837.36 toks/s, output: 3728.12 toks/s]\n",
      "Processed prompts:  61%|██████    | 303/500 [00:15<00:19, 10.31it/s, est. speed input: 2786.54 toks/s, output: 3672.70 toks/s]\n",
      "Processed prompts:  61%|██████    | 306/500 [00:15<00:14, 13.03it/s, est. speed input: 2793.60 toks/s, output: 3682.13 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 308/500 [00:15<00:14, 12.86it/s, est. speed input: 2783.34 toks/s, output: 3671.65 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 310/500 [00:16<00:18, 10.05it/s, est. speed input: 2744.73 toks/s, output: 3620.36 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 312/500 [00:16<00:23,  8.08it/s, est. speed input: 2698.94 toks/s, output: 3572.59 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 314/500 [00:16<00:19,  9.59it/s, est. speed input: 2698.64 toks/s, output: 3577.54 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 316/500 [00:16<00:20,  8.86it/s, est. speed input: 2672.70 toks/s, output: 3549.44 toks/s]\n",
      "Processed prompts:  64%|██████▎   | 318/500 [00:17<00:25,  7.18it/s, est. speed input: 2625.87 toks/s, output: 3497.13 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 321/500 [00:17<00:17, 10.04it/s, est. speed input: 2634.60 toks/s, output: 3526.77 toks/s]\n",
      "Processed prompts:  65%|██████▍   | 324/500 [00:17<00:14, 12.43it/s, est. speed input: 2638.57 toks/s, output: 3540.61 toks/s]\n",
      "Processed prompts:  65%|██████▌   | 326/500 [00:18<00:27,  6.34it/s, est. speed input: 2542.19 toks/s, output: 3419.67 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 328/500 [00:18<00:27,  6.33it/s, est. speed input: 2514.03 toks/s, output: 3411.13 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 331/500 [00:19<00:29,  5.75it/s, est. speed input: 2457.23 toks/s, output: 3369.37 toks/s]\n",
      "Processed prompts:  66%|██████▋   | 332/500 [00:19<00:30,  5.58it/s, est. speed input: 2438.16 toks/s, output: 3347.66 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 333/500 [00:19<00:37,  4.44it/s, est. speed input: 2390.74 toks/s, output: 3307.66 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 334/500 [00:20<00:41,  4.03it/s, est. speed input: 2357.42 toks/s, output: 3268.99 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 335/500 [00:20<00:35,  4.62it/s, est. speed input: 2352.16 toks/s, output: 3273.58 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 337/500 [00:20<00:39,  4.10it/s, est. speed input: 2300.76 toks/s, output: 3215.80 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 338/500 [00:20<00:35,  4.55it/s, est. speed input: 2293.04 toks/s, output: 3213.65 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 339/500 [00:21<00:48,  3.29it/s, est. speed input: 2238.39 toks/s, output: 3151.86 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 341/500 [00:21<00:38,  4.08it/s, est. speed input: 2218.93 toks/s, output: 3145.58 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 342/500 [00:26<03:08,  1.19s/it, est. speed input: 1847.14 toks/s, output: 2634.83 toks/s]\n",
      "Processed prompts:  69%|██████▊   | 343/500 [00:28<03:29,  1.33s/it, est. speed input: 1736.06 toks/s, output: 2491.21 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 344/500 [00:28<02:47,  1.08s/it, est. speed input: 1720.38 toks/s, output: 2497.38 toks/s]\n",
      "Processed prompts:  86%|████████▌ | 430/500 [00:30<00:03, 18.39it/s, est. speed input: 2018.20 toks/s, output: 5243.02 toks/s]\n",
      "Processed prompts:  86%|████████▋ | 432/500 [00:30<00:03, 17.19it/s, est. speed input: 2004.24 toks/s, output: 5249.67 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 434/500 [00:30<00:04, 16.22it/s, est. speed input: 1995.33 toks/s, output: 5268.43 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 437/500 [00:31<00:03, 16.21it/s, est. speed input: 1997.18 toks/s, output: 5335.44 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 440/500 [00:31<00:03, 15.98it/s, est. speed input: 1997.64 toks/s, output: 5397.61 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 442/500 [00:31<00:03, 14.82it/s, est. speed input: 1991.96 toks/s, output: 5422.95 toks/s]\n",
      "Processed prompts:  89%|████████▉ | 444/500 [00:31<00:03, 15.08it/s, est. speed input: 1993.69 toks/s, output: 5467.75 toks/s]\n",
      "Processed prompts:  89%|████████▉ | 447/500 [00:32<00:04, 12.64it/s, est. speed input: 1982.64 toks/s, output: 5496.88 toks/s]\n",
      "Processed prompts:  90%|████████▉ | 449/500 [00:32<00:03, 12.91it/s, est. speed input: 1982.91 toks/s, output: 5536.98 toks/s]\n",
      "Processed prompts:  90%|█████████ | 451/500 [00:32<00:03, 13.20it/s, est. speed input: 1983.22 toks/s, output: 5576.83 toks/s]\n",
      "Processed prompts:  91%|█████████ | 453/500 [00:32<00:03, 13.47it/s, est. speed input: 1983.64 toks/s, output: 5616.24 toks/s]\n",
      "Processed prompts:  91%|█████████ | 455/500 [00:32<00:03, 12.01it/s, est. speed input: 1978.70 toks/s, output: 5639.89 toks/s]\n",
      "Processed prompts:  91%|█████████▏| 457/500 [00:33<00:05,  8.41it/s, est. speed input: 1960.26 toks/s, output: 5624.54 toks/s]\n",
      "Processed prompts:  92%|█████████▏| 459/500 [00:33<00:04,  9.44it/s, est. speed input: 1960.64 toks/s, output: 5662.52 toks/s]\n",
      "Processed prompts:  92%|█████████▏| 461/500 [00:33<00:04,  8.51it/s, est. speed input: 1951.74 toks/s, output: 5673.48 toks/s]\n",
      "Processed prompts:  92%|█████████▏| 462/500 [00:33<00:05,  7.01it/s, est. speed input: 1940.36 toks/s, output: 5658.15 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 464/500 [00:34<00:05,  6.96it/s, est. speed input: 1932.27 toks/s, output: 5669.80 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 465/500 [00:34<00:05,  6.66it/s, est. speed input: 1926.45 toks/s, output: 5670.12 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 466/500 [00:34<00:04,  6.82it/s, est. speed input: 1923.07 toks/s, output: 5677.89 toks/s]\n",
      "Processed prompts:  94%|█████████▎| 468/500 [00:34<00:04,  7.26it/s, est. speed input: 1917.78 toks/s, output: 5696.56 toks/s]\n",
      "Processed prompts:  94%|█████████▍| 470/500 [00:34<00:03,  8.82it/s, est. speed input: 1918.64 toks/s, output: 5733.20 toks/s]\n",
      "Processed prompts:  94%|█████████▍| 472/500 [00:35<00:03,  7.05it/s, est. speed input: 1905.10 toks/s, output: 5726.54 toks/s]\n",
      "Processed prompts:  95%|█████████▍| 474/500 [00:35<00:03,  7.58it/s, est. speed input: 1901.22 toks/s, output: 5748.40 toks/s]\n",
      "Processed prompts:  95%|█████████▌| 476/500 [00:35<00:02,  9.29it/s, est. speed input: 1903.43 toks/s, output: 5788.15 toks/s]\n",
      "Processed prompts:  96%|█████████▌| 480/500 [00:35<00:01, 14.32it/s, est. speed input: 1913.59 toks/s, output: 5884.78 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 484/500 [00:35<00:00, 16.24it/s, est. speed input: 1918.96 toks/s, output: 5966.41 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 488/500 [00:36<00:00, 19.63it/s, est. speed input: 1928.06 toks/s, output: 6058.44 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 492/500 [00:36<00:00, 18.01it/s, est. speed input: 1930.07 toks/s, output: 6128.28 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 495/500 [00:36<00:00, 15.27it/s, est. speed input: 1927.26 toks/s, output: 6165.72 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 497/500 [00:36<00:00, 13.15it/s, est. speed input: 1922.75 toks/s, output: 6182.04 toks/s]\n",
      "Processed prompts: 100%|█████████▉| 499/500 [00:37<00:00,  8.76it/s, est. speed input: 1905.12 toks/s, output: 6155.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 500/500 [00:37<00:00, 13.37it/s, est. speed input: 1905.78 toks/s, output: 6173.09 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 4472.14it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:04<01:02,  1.05s/it, est. speed input: 137.48 toks/s, output: 129.37 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:06<00:44,  1.25it/s, est. speed input: 170.01 toks/s, output: 161.63 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:07<00:29,  1.75it/s, est. speed input: 215.80 toks/s, output: 246.01 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:08<00:20,  2.30it/s, est. speed input: 257.05 toks/s, output: 332.57 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:11<00:21,  2.06it/s, est. speed input: 255.15 toks/s, output: 371.55 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:14<00:24,  1.64it/s, est. speed input: 235.27 toks/s, output: 367.17 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:15<00:18,  1.91it/s, est. speed input: 250.04 toks/s, output: 416.85 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:17<00:14,  2.21it/s, est. speed input: 266.11 toks/s, output: 465.69 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:21<00:19,  1.47it/s, est. speed input: 234.28 toks/s, output: 451.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:22<00:00,  2.86it/s, est. speed input: 404.71 toks/s, output: 1090.10 toks/s]\n",
      "Adding requests: 100%|██████████| 500/500 [00:00<00:00, 9920.63it/s]\n",
      "Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   0%|          | 1/500 [00:02<17:56,  2.16s/it, est. speed input: 65.38 toks/s, output: 32.92 toks/s]\n",
      "Processed prompts:   1%|          | 3/500 [00:02<05:40,  1.46it/s, est. speed input: 169.29 toks/s, output: 90.45 toks/s]\n",
      "Processed prompts:   1%|          | 5/500 [00:02<03:06,  2.65it/s, est. speed input: 265.36 toks/s, output: 149.92 toks/s]\n",
      "Processed prompts:   1%|          | 6/500 [00:02<02:35,  3.18it/s, est. speed input: 302.90 toks/s, output: 175.62 toks/s]\n",
      "Processed prompts:   2%|▏         | 8/500 [00:02<01:45,  4.64it/s, est. speed input: 380.50 toks/s, output: 230.44 toks/s]\n",
      "Processed prompts:   2%|▏         | 12/500 [00:03<00:56,  8.61it/s, est. speed input: 542.44 toks/s, output: 350.76 toks/s]\n",
      "Processed prompts:   3%|▎         | 14/500 [00:03<00:48, 10.09it/s, est. speed input: 610.33 toks/s, output: 405.24 toks/s]\n",
      "Processed prompts:   3%|▎         | 17/500 [00:03<00:36, 13.10it/s, est. speed input: 717.84 toks/s, output: 490.36 toks/s]\n",
      "Processed prompts:   4%|▍         | 20/500 [00:03<00:30, 15.92it/s, est. speed input: 817.07 toks/s, output: 573.99 toks/s]\n",
      "Processed prompts:   5%|▍         | 23/500 [00:03<00:28, 16.48it/s, est. speed input: 895.51 toks/s, output: 647.53 toks/s]\n",
      "Processed prompts:   5%|▌         | 27/500 [00:03<00:23, 20.30it/s, est. speed input: 1016.32 toks/s, output: 758.78 toks/s]\n",
      "Processed prompts:   6%|▌         | 31/500 [00:03<00:19, 23.77it/s, est. speed input: 1131.83 toks/s, output: 868.89 toks/s]\n",
      "Processed prompts:   8%|▊         | 38/500 [00:04<00:18, 25.15it/s, est. speed input: 1303.28 toks/s, output: 1040.93 toks/s]\n",
      "Processed prompts:   9%|▉         | 46/500 [00:04<00:12, 35.01it/s, est. speed input: 1537.58 toks/s, output: 1280.72 toks/s]\n",
      "Processed prompts:  10%|█         | 51/500 [00:04<00:14, 30.03it/s, est. speed input: 1619.07 toks/s, output: 1381.93 toks/s]\n",
      "Processed prompts:  11%|█         | 56/500 [00:04<00:14, 29.80it/s, est. speed input: 1712.09 toks/s, output: 1497.20 toks/s]\n",
      "Processed prompts:  13%|█▎        | 63/500 [00:04<00:11, 36.64it/s, est. speed input: 1881.86 toks/s, output: 1696.66 toks/s]\n",
      "Processed prompts:  14%|█▎        | 68/500 [00:04<00:11, 36.29it/s, est. speed input: 1971.29 toks/s, output: 1815.66 toks/s]\n",
      "Processed prompts:  14%|█▍        | 72/500 [00:05<00:12, 34.06it/s, est. speed input: 2029.60 toks/s, output: 1901.09 toks/s]\n",
      "Processed prompts:  16%|█▌        | 80/500 [00:05<00:09, 43.06it/s, est. speed input: 2205.56 toks/s, output: 2128.47 toks/s]\n",
      "Processed prompts:  17%|█▋        | 85/500 [00:05<00:10, 40.71it/s, est. speed input: 2281.15 toks/s, output: 2240.80 toks/s]\n",
      "Processed prompts:  18%|█▊        | 90/500 [00:05<00:09, 41.75it/s, est. speed input: 2366.30 toks/s, output: 2363.70 toks/s]\n",
      "Processed prompts:  19%|█▉        | 95/500 [00:05<00:10, 39.76it/s, est. speed input: 2435.61 toks/s, output: 2473.39 toks/s]\n",
      "Processed prompts:  20%|██        | 100/500 [00:05<00:09, 41.09it/s, est. speed input: 2512.39 toks/s, output: 2594.76 toks/s]\n",
      "Processed prompts:  21%|██        | 106/500 [00:05<00:08, 44.25it/s, est. speed input: 2609.52 toks/s, output: 2746.45 toks/s]\n",
      "Processed prompts:  23%|██▎       | 113/500 [00:05<00:08, 46.29it/s, est. speed input: 2716.67 toks/s, output: 2902.92 toks/s]\n",
      "Processed prompts:  24%|██▎       | 118/500 [00:06<00:08, 42.89it/s, est. speed input: 2771.25 toks/s, output: 2988.49 toks/s]\n",
      "Processed prompts:  25%|██▍       | 123/500 [00:06<00:11, 34.10it/s, est. speed input: 2785.27 toks/s, output: 3050.21 toks/s]\n",
      "Processed prompts:  25%|██▌       | 127/500 [00:06<00:12, 30.89it/s, est. speed input: 2800.38 toks/s, output: 3106.43 toks/s]\n",
      "Processed prompts:  26%|██▌       | 131/500 [00:06<00:12, 29.90it/s, est. speed input: 2824.49 toks/s, output: 3174.65 toks/s]\n",
      "Processed prompts:  27%|██▋       | 135/500 [00:06<00:12, 29.42it/s, est. speed input: 2848.79 toks/s, output: 3230.86 toks/s]\n",
      "Processed prompts:  28%|██▊       | 139/500 [00:06<00:11, 30.72it/s, est. speed input: 2883.50 toks/s, output: 3257.56 toks/s]\n",
      "Processed prompts:  29%|██▊       | 143/500 [00:07<00:13, 26.65it/s, est. speed input: 2882.51 toks/s, output: 3283.89 toks/s]\n",
      "Processed prompts:  29%|██▉       | 147/500 [00:07<00:12, 28.67it/s, est. speed input: 2917.08 toks/s, output: 3350.47 toks/s]\n",
      "Processed prompts:  30%|███       | 151/500 [00:07<00:12, 28.47it/s, est. speed input: 2937.87 toks/s, output: 3380.70 toks/s]\n",
      "Processed prompts:  31%|███       | 154/500 [00:07<00:13, 26.19it/s, est. speed input: 2938.85 toks/s, output: 3363.08 toks/s]\n",
      "Processed prompts:  32%|███▏      | 158/500 [00:07<00:16, 21.33it/s, est. speed input: 2912.30 toks/s, output: 3363.43 toks/s]\n",
      "Processed prompts:  32%|███▏      | 161/500 [00:07<00:15, 22.35it/s, est. speed input: 2923.20 toks/s, output: 3379.97 toks/s]\n",
      "Processed prompts:  33%|███▎      | 164/500 [00:08<00:16, 20.82it/s, est. speed input: 2913.93 toks/s, output: 3397.85 toks/s]\n",
      "Processed prompts:  33%|███▎      | 167/500 [00:08<00:15, 22.02it/s, est. speed input: 2924.66 toks/s, output: 3402.82 toks/s]\n",
      "Processed prompts:  34%|███▍      | 170/500 [00:08<00:16, 20.57it/s, est. speed input: 2916.40 toks/s, output: 3381.60 toks/s]\n",
      "Processed prompts:  35%|███▌      | 175/500 [00:08<00:12, 25.81it/s, est. speed input: 2959.44 toks/s, output: 3488.59 toks/s]\n",
      "Processed prompts:  36%|███▌      | 179/500 [00:08<00:12, 24.75it/s, est. speed input: 2965.59 toks/s, output: 3514.84 toks/s]\n",
      "Processed prompts:  36%|███▋      | 182/500 [00:08<00:13, 23.60it/s, est. speed input: 2965.70 toks/s, output: 3559.31 toks/s]\n",
      "Processed prompts:  37%|███▋      | 186/500 [00:08<00:12, 24.80it/s, est. speed input: 2981.40 toks/s, output: 3580.02 toks/s]\n",
      "Processed prompts:  38%|███▊      | 191/500 [00:09<00:11, 27.43it/s, est. speed input: 3010.11 toks/s, output: 3599.41 toks/s]\n",
      "Processed prompts:  40%|███▉      | 198/500 [00:09<00:08, 35.58it/s, est. speed input: 3080.80 toks/s, output: 3686.72 toks/s]\n",
      "Processed prompts:  40%|████      | 202/500 [00:09<00:09, 31.21it/s, est. speed input: 3084.08 toks/s, output: 3711.75 toks/s]\n",
      "Processed prompts:  41%|████▏     | 207/500 [00:09<00:08, 34.02it/s, est. speed input: 3121.34 toks/s, output: 3783.74 toks/s]\n",
      "Processed prompts:  42%|████▏     | 212/500 [00:09<00:10, 28.40it/s, est. speed input: 3116.63 toks/s, output: 3804.69 toks/s]\n",
      "Processed prompts:  43%|████▎     | 216/500 [00:09<00:09, 29.29it/s, est. speed input: 3134.80 toks/s, output: 3811.89 toks/s]\n",
      "Processed prompts:  44%|████▍     | 220/500 [00:09<00:10, 27.17it/s, est. speed input: 3137.08 toks/s, output: 3815.97 toks/s]\n",
      "Processed prompts:  45%|████▍     | 223/500 [00:10<00:14, 19.04it/s, est. speed input: 3080.93 toks/s, output: 3746.54 toks/s]\n",
      "Processed prompts:  45%|████▌     | 226/500 [00:10<00:14, 18.51it/s, est. speed input: 3069.71 toks/s, output: 3744.66 toks/s]\n",
      "Processed prompts:  46%|████▌     | 229/500 [00:10<00:14, 18.07it/s, est. speed input: 3058.27 toks/s, output: 3752.48 toks/s]\n",
      "Processed prompts:  46%|████▌     | 231/500 [00:10<00:15, 17.83it/s, est. speed input: 3051.68 toks/s, output: 3761.58 toks/s]\n",
      "Processed prompts:  47%|████▋     | 234/500 [00:10<00:13, 19.60it/s, est. speed input: 3057.86 toks/s, output: 3770.23 toks/s]\n",
      "Processed prompts:  47%|████▋     | 237/500 [00:11<00:13, 19.82it/s, est. speed input: 3056.00 toks/s, output: 3766.02 toks/s]\n",
      "Processed prompts:  48%|████▊     | 241/500 [00:11<00:11, 21.65it/s, est. speed input: 3064.84 toks/s, output: 3787.54 toks/s]\n",
      "Processed prompts:  49%|████▉     | 244/500 [00:11<00:13, 18.85it/s, est. speed input: 3045.48 toks/s, output: 3753.78 toks/s]\n",
      "Processed prompts:  50%|████▉     | 249/500 [00:11<00:10, 22.88it/s, est. speed input: 3067.56 toks/s, output: 3794.30 toks/s]\n",
      "Processed prompts:  50%|█████     | 252/500 [00:11<00:10, 23.32it/s, est. speed input: 3072.47 toks/s, output: 3821.37 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 258/500 [00:11<00:08, 28.54it/s, est. speed input: 3106.42 toks/s, output: 3881.29 toks/s]\n",
      "Processed prompts:  52%|█████▏    | 261/500 [00:11<00:09, 26.42it/s, est. speed input: 3105.18 toks/s, output: 3877.81 toks/s]\n",
      "Processed prompts:  53%|█████▎    | 264/500 [00:12<00:10, 23.45it/s, est. speed input: 3096.69 toks/s, output: 3888.99 toks/s]\n",
      "Processed prompts:  53%|█████▎    | 267/500 [00:12<00:11, 19.47it/s, est. speed input: 3073.61 toks/s, output: 3842.49 toks/s]\n",
      "Processed prompts:  54%|█████▍    | 271/500 [00:12<00:13, 17.36it/s, est. speed input: 3051.14 toks/s, output: 3825.81 toks/s]\n",
      "Processed prompts:  55%|█████▍    | 274/500 [00:12<00:12, 18.25it/s, est. speed input: 3050.83 toks/s, output: 3820.65 toks/s]\n",
      "Processed prompts:  55%|█████▌    | 276/500 [00:12<00:12, 17.25it/s, est. speed input: 3039.65 toks/s, output: 3829.93 toks/s]\n",
      "Processed prompts:  56%|█████▌    | 279/500 [00:13<00:12, 18.30it/s, est. speed input: 3039.89 toks/s, output: 3842.17 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 284/500 [00:13<00:08, 24.28it/s, est. speed input: 3068.42 toks/s, output: 3897.59 toks/s]\n",
      "Processed prompts:  57%|█████▋    | 287/500 [00:13<00:11, 17.78it/s, est. speed input: 3033.01 toks/s, output: 3860.34 toks/s]\n",
      "Processed prompts:  58%|█████▊    | 290/500 [00:13<00:12, 16.25it/s, est. speed input: 3014.18 toks/s, output: 3828.10 toks/s]\n",
      "Processed prompts:  59%|█████▊    | 293/500 [00:13<00:11, 17.41it/s, est. speed input: 3014.35 toks/s, output: 3826.19 toks/s]\n",
      "Processed prompts:  59%|█████▉    | 297/500 [00:13<00:10, 20.16it/s, est. speed input: 3024.43 toks/s, output: 3838.40 toks/s]\n",
      "Processed prompts:  60%|██████    | 301/500 [00:14<00:08, 22.25it/s, est. speed input: 3034.32 toks/s, output: 3845.75 toks/s]\n",
      "Processed prompts:  61%|██████    | 304/500 [00:14<00:08, 23.32it/s, est. speed input: 3040.43 toks/s, output: 3868.49 toks/s]\n",
      "Processed prompts:  61%|██████▏   | 307/500 [00:14<00:08, 21.57it/s, est. speed input: 3034.81 toks/s, output: 3879.60 toks/s]\n",
      "Processed prompts:  62%|██████▏   | 310/500 [00:14<00:09, 20.41it/s, est. speed input: 3029.33 toks/s, output: 3861.40 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 313/500 [00:14<00:12, 15.12it/s, est. speed input: 2991.44 toks/s, output: 3834.65 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 315/500 [00:15<00:12, 14.40it/s, est. speed input: 2978.00 toks/s, output: 3812.93 toks/s]\n",
      "Processed prompts:  63%|██████▎   | 317/500 [00:15<00:15, 11.59it/s, est. speed input: 2941.74 toks/s, output: 3784.82 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 319/500 [00:15<00:20,  8.62it/s, est. speed input: 2883.46 toks/s, output: 3710.92 toks/s]\n",
      "Processed prompts:  64%|██████▍   | 322/500 [00:15<00:17, 10.21it/s, est. speed input: 2875.38 toks/s, output: 3726.44 toks/s]\n",
      "Processed prompts:  65%|██████▍   | 324/500 [00:16<00:16, 10.68it/s, est. speed input: 2864.44 toks/s, output: 3717.27 toks/s]\n",
      "Processed prompts:  65%|██████▌   | 326/500 [00:16<00:15, 11.52it/s, est. speed input: 2858.16 toks/s, output: 3717.48 toks/s]\n",
      "Processed prompts:  66%|██████▌   | 330/500 [00:16<00:10, 15.65it/s, est. speed input: 2869.87 toks/s, output: 3758.05 toks/s]\n",
      "Processed prompts:  66%|██████▋   | 332/500 [00:16<00:10, 15.50it/s, est. speed input: 2864.24 toks/s, output: 3778.52 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 334/500 [00:16<00:10, 15.38it/s, est. speed input: 2858.70 toks/s, output: 3797.22 toks/s]\n",
      "Processed prompts:  67%|██████▋   | 336/500 [00:16<00:14, 11.15it/s, est. speed input: 2822.33 toks/s, output: 3754.62 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 338/500 [00:17<00:18,  8.60it/s, est. speed input: 2777.81 toks/s, output: 3703.78 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 340/500 [00:17<00:21,  7.34it/s, est. speed input: 2735.12 toks/s, output: 3661.11 toks/s]\n",
      "Processed prompts:  68%|██████▊   | 342/500 [00:17<00:19,  8.03it/s, est. speed input: 2721.84 toks/s, output: 3655.60 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 344/500 [00:18<00:32,  4.77it/s, est. speed input: 2615.63 toks/s, output: 3524.39 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 345/500 [00:19<00:35,  4.31it/s, est. speed input: 2576.66 toks/s, output: 3497.12 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 346/500 [00:19<00:31,  4.84it/s, est. speed input: 2569.94 toks/s, output: 3503.26 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 347/500 [00:20<01:00,  2.53it/s, est. speed input: 2441.69 toks/s, output: 3339.68 toks/s]\n",
      "Processed prompts:  70%|██████▉   | 348/500 [00:20<00:56,  2.71it/s, est. speed input: 2414.57 toks/s, output: 3322.06 toks/s]\n",
      "Processed prompts:  70%|███████   | 350/500 [00:21<00:47,  3.13it/s, est. speed input: 2371.38 toks/s, output: 3288.34 toks/s]\n",
      "Processed prompts:  70%|███████   | 351/500 [00:21<01:05,  2.27it/s, est. speed input: 2285.03 toks/s, output: 3177.69 toks/s]\n",
      "Processed prompts:  70%|███████   | 352/500 [00:24<02:13,  1.11it/s, est. speed input: 2070.61 toks/s, output: 2894.37 toks/s]\n",
      "Processed prompts:  71%|███████   | 353/500 [00:28<04:14,  1.73s/it, est. speed input: 1773.96 toks/s, output: 2508.92 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 433/500 [00:30<00:05, 12.88it/s, est. speed input: 2052.94 toks/s, output: 5091.28 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 435/500 [00:30<00:05, 11.96it/s, est. speed input: 2027.93 toks/s, output: 5072.91 toks/s]\n",
      "Processed prompts:  87%|████████▋ | 437/500 [00:31<00:05, 11.13it/s, est. speed input: 2008.42 toks/s, output: 5067.07 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 438/500 [00:31<00:05, 10.58it/s, est. speed input: 1997.62 toks/s, output: 5060.88 toks/s]\n",
      "Processed prompts:  88%|████████▊ | 442/500 [00:31<00:05, 10.41it/s, est. speed input: 1989.30 toks/s, output: 5123.55 toks/s]\n",
      "Processed prompts:  89%|████████▉ | 445/500 [00:31<00:05, 10.22it/s, est. speed input: 1982.29 toks/s, output: 5167.25 toks/s]\n",
      "Processed prompts:  89%|████████▉ | 446/500 [00:32<00:05,  9.91it/s, est. speed input: 1977.80 toks/s, output: 5175.63 toks/s]\n",
      "Processed prompts:  89%|████████▉ | 447/500 [00:32<00:05,  9.44it/s, est. speed input: 1972.22 toks/s, output: 5181.31 toks/s]\n",
      "Processed prompts:  90%|████████▉ | 448/500 [00:32<00:05,  9.35it/s, est. speed input: 1969.53 toks/s, output: 5194.42 toks/s]\n",
      "Processed prompts:  91%|█████████ | 455/500 [00:32<00:03, 14.16it/s, est. speed input: 1984.79 toks/s, output: 5373.76 toks/s]\n",
      "Processed prompts:  91%|█████████▏| 457/500 [00:32<00:03, 13.42it/s, est. speed input: 1982.22 toks/s, output: 5405.57 toks/s]\n",
      "Processed prompts:  92%|█████████▏| 461/500 [00:33<00:02, 15.43it/s, est. speed input: 1988.77 toks/s, output: 5500.04 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 463/500 [00:33<00:02, 15.84it/s, est. speed input: 1990.76 toks/s, output: 5543.21 toks/s]\n",
      "Processed prompts:  93%|█████████▎| 465/500 [00:33<00:02, 12.73it/s, est. speed input: 1983.08 toks/s, output: 5559.70 toks/s]\n",
      "Processed prompts:  94%|█████████▎| 468/500 [00:33<00:02, 12.89it/s, est. speed input: 1982.63 toks/s, output: 5613.59 toks/s]\n",
      "Processed prompts:  94%|█████████▍| 471/500 [00:34<00:02, 10.73it/s, est. speed input: 1972.66 toks/s, output: 5640.52 toks/s]\n",
      "Processed prompts:  95%|█████████▍| 474/500 [00:34<00:02, 10.86it/s, est. speed input: 1969.92 toks/s, output: 5685.99 toks/s]\n",
      "Processed prompts:  95%|█████████▌| 476/500 [00:34<00:02, 11.88it/s, est. speed input: 1971.63 toks/s, output: 5726.54 toks/s]\n",
      "Processed prompts:  96%|█████████▌| 478/500 [00:34<00:01, 11.74it/s, est. speed input: 1969.85 toks/s, output: 5756.56 toks/s]\n",
      "Processed prompts:  96%|█████████▌| 480/500 [00:34<00:01, 11.27it/s, est. speed input: 1966.81 toks/s, output: 5782.70 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 483/500 [00:35<00:01, 10.99it/s, est. speed input: 1962.95 toks/s, output: 5823.22 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 485/500 [00:35<00:01,  9.65it/s, est. speed input: 1955.46 toks/s, output: 5834.78 toks/s]\n",
      "Processed prompts:  97%|█████████▋| 487/500 [00:35<00:01,  9.31it/s, est. speed input: 1950.50 toks/s, output: 5853.63 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 489/500 [00:35<00:01,  9.85it/s, est. speed input: 1949.12 toks/s, output: 5882.77 toks/s]\n",
      "Processed prompts:  98%|█████████▊| 491/500 [00:35<00:00, 11.00it/s, est. speed input: 1950.22 toks/s, output: 5918.85 toks/s]\n",
      "Processed prompts:  99%|█████████▊| 493/500 [00:35<00:00, 12.46it/s, est. speed input: 1952.33 toks/s, output: 5958.04 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 495/500 [00:36<00:00,  7.10it/s, est. speed input: 1929.27 toks/s, output: 5920.12 toks/s]\n",
      "Processed prompts:  99%|█████████▉| 497/500 [00:36<00:00,  7.65it/s, est. speed input: 1925.82 toks/s, output: 5941.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 500/500 [00:37<00:00, 13.48it/s, est. speed input: 1920.88 toks/s, output: 5973.82 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 3652.98it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:05<01:27,  1.46s/it, est. speed input: 99.06 toks/s, output: 133.21 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:08<00:52,  1.08it/s, est. speed input: 143.14 toks/s, output: 249.01 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:08<00:29,  1.78it/s, est. speed input: 200.90 toks/s, output: 364.89 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:10<00:27,  1.73it/s, est. speed input: 209.32 toks/s, output: 374.96 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:11<00:18,  2.40it/s, est. speed input: 248.81 toks/s, output: 475.81 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:12<00:13,  3.03it/s, est. speed input: 282.16 toks/s, output: 546.13 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:13<00:10,  3.41it/s, est. speed input: 306.61 toks/s, output: 583.65 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:13<00:06,  4.69it/s, est. speed input: 346.63 toks/s, output: 675.22 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:14<00:07,  3.93it/s, est. speed input: 353.34 toks/s, output: 706.20 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:15<00:05,  4.72it/s, est. speed input: 380.42 toks/s, output: 778.06 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 44/64 [00:18<00:08,  2.50it/s, est. speed input: 343.35 toks/s, output: 733.40 toks/s]\n",
      "Processed prompts:  75%|███████▌  | 48/64 [00:22<00:09,  1.71it/s, est. speed input: 306.51 toks/s, output: 694.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:22<00:00,  2.84it/s, est. speed input: 406.25 toks/s, output: 1100.05 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 4524.90it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:08<02:01,  2.02s/it, est. speed input: 69.77 toks/s, output: 80.65 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:08<00:48,  1.16it/s, est. speed input: 137.73 toks/s, output: 182.76 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:09<00:29,  1.76it/s, est. speed input: 187.57 toks/s, output: 262.81 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:11<00:25,  1.87it/s, est. speed input: 206.96 toks/s, output: 303.70 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:12<00:19,  2.21it/s, est. speed input: 232.27 toks/s, output: 352.29 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:12<00:08,  4.04it/s, est. speed input: 314.82 toks/s, output: 503.60 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:14<00:06,  4.26it/s, est. speed input: 355.95 toks/s, output: 612.87 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:17<00:08,  2.96it/s, est. speed input: 332.26 toks/s, output: 614.04 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 44/64 [00:17<00:05,  3.65it/s, est. speed input: 358.53 toks/s, output: 680.33 toks/s]\n",
      "Processed prompts:  75%|███████▌  | 48/64 [00:17<00:03,  4.53it/s, est. speed input: 385.56 toks/s, output: 771.56 toks/s]\n",
      "Processed prompts:  81%|████████▏ | 52/64 [00:18<00:02,  4.83it/s, est. speed input: 402.52 toks/s, output: 837.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:24<00:00,  2.58it/s, est. speed input: 368.09 toks/s, output: 836.75 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 4534.08it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:09<02:18,  2.31s/it, est. speed input: 61.12 toks/s, output: 55.60 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:11<01:12,  1.29s/it, est. speed input: 99.32 toks/s, output: 125.62 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:14<00:52,  1.00s/it, est. speed input: 120.39 toks/s, output: 164.38 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:14<00:29,  1.61it/s, est. speed input: 159.64 toks/s, output: 243.72 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:14<00:19,  2.26it/s, est. speed input: 192.92 toks/s, output: 305.36 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:15<00:14,  2.82it/s, est. speed input: 220.93 toks/s, output: 351.53 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:15<00:06,  5.02it/s, est. speed input: 287.05 toks/s, output: 462.39 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:16<00:05,  5.50it/s, est. speed input: 312.88 toks/s, output: 510.53 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:17<00:05,  4.25it/s, est. speed input: 318.73 toks/s, output: 534.06 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 44/64 [00:18<00:03,  5.29it/s, est. speed input: 344.92 toks/s, output: 607.90 toks/s]\n",
      "Processed prompts:  75%|███████▌  | 48/64 [00:19<00:04,  3.83it/s, est. speed input: 342.67 toks/s, output: 626.22 toks/s]\n",
      "Processed prompts:  81%|████████▏ | 52/64 [00:22<00:04,  2.57it/s, est. speed input: 325.12 toks/s, output: 610.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:27<00:00,  2.30it/s, est. speed input: 326.40 toks/s, output: 697.97 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 4656.78it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:12<03:09,  3.16s/it, est. speed input: 45.29 toks/s, output: 59.15 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:13<01:18,  1.40s/it, est. speed input: 84.87 toks/s, output: 108.34 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:13<00:43,  1.20it/s, est. speed input: 121.57 toks/s, output: 173.46 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:15<00:31,  1.54it/s, est. speed input: 147.24 toks/s, output: 219.37 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:17<00:25,  1.71it/s, est. speed input: 163.75 toks/s, output: 260.87 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:17<00:16,  2.43it/s, est. speed input: 194.03 toks/s, output: 316.04 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:18<00:11,  3.00it/s, est. speed input: 217.58 toks/s, output: 388.04 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:18<00:07,  4.09it/s, est. speed input: 246.34 toks/s, output: 450.86 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:18<00:05,  5.12it/s, est. speed input: 272.28 toks/s, output: 504.16 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:19<00:05,  4.71it/s, est. speed input: 286.74 toks/s, output: 540.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:28<00:00,  2.29it/s, est. speed input: 324.54 toks/s, output: 882.67 toks/s]\n",
      "Adding requests: 100%|██████████| 16/16 [00:00<00:00, 5049.58it/s]\n",
      "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts:   6%|▋         | 4/64 [00:06<01:39,  1.65s/it, est. speed input: 84.62 toks/s, output: 75.55 toks/s]\n",
      "Processed prompts:  12%|█▎        | 8/64 [00:08<00:52,  1.06it/s, est. speed input: 135.96 toks/s, output: 193.32 toks/s]\n",
      "Processed prompts:  19%|█▉        | 12/64 [00:09<00:33,  1.54it/s, est. speed input: 178.60 toks/s, output: 254.16 toks/s]\n",
      "Processed prompts:  25%|██▌       | 16/64 [00:09<00:20,  2.33it/s, est. speed input: 228.99 toks/s, output: 339.76 toks/s]\n",
      "Processed prompts:  31%|███▏      | 20/64 [00:10<00:13,  3.17it/s, est. speed input: 274.67 toks/s, output: 391.73 toks/s]\n",
      "Processed prompts:  38%|███▊      | 24/64 [00:11<00:10,  3.78it/s, est. speed input: 310.04 toks/s, output: 473.90 toks/s]\n",
      "Processed prompts:  44%|████▍     | 28/64 [00:12<00:11,  3.20it/s, est. speed input: 315.30 toks/s, output: 520.03 toks/s]\n",
      "Processed prompts:  50%|█████     | 32/64 [00:13<00:08,  3.74it/s, est. speed input: 342.57 toks/s, output: 585.25 toks/s]\n",
      "Processed prompts:  56%|█████▋    | 36/64 [00:14<00:08,  3.49it/s, est. speed input: 350.98 toks/s, output: 605.31 toks/s]\n",
      "Processed prompts:  62%|██████▎   | 40/64 [00:17<00:09,  2.58it/s, est. speed input: 334.70 toks/s, output: 625.97 toks/s]\n",
      "Processed prompts:  69%|██████▉   | 44/64 [00:18<00:07,  2.65it/s, est. speed input: 340.06 toks/s, output: 647.26 toks/s]\n",
      "Processed prompts:  75%|███████▌  | 48/64 [00:19<00:04,  3.30it/s, est. speed input: 360.74 toks/s, output: 720.08 toks/s]\n",
      "Processed prompts:  81%|████████▏ | 52/64 [00:21<00:04,  2.75it/s, est. speed input: 353.58 toks/s, output: 715.11 toks/s]\n"
     ]
    }
   ],
   "source": [
    "VLLM_GPUS = \"4,5\"\n",
    "# start hte ray instance \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = VLLM_GPUS\n",
    "ray.init()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use ray placement group to start the inference engines on gpus 4 and 5 \n",
    "\n",
    "pg_inference = placement_group([{\"GPU\": 1, \"CPU\": 0}] * 2)\n",
    "ray.get(pg_inference.ready())\n",
    "scheduling_inference = PlacementGroupSchedulingStrategy(\n",
    "    placement_group=pg_inference,\n",
    "    placement_group_capture_child_tasks=True,\n",
    "    placement_group_bundle_index=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define our VLLM inference engine class. we will first wrap the custom class extending VLLM in a ray remote (to my understanding, basically its async wrapper) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: understand why this is needed? \n",
    "\n",
    "class MyLLM(LLM):\n",
    "    \"\"\"Configure the vLLM worker for Ray placement group execution.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Remove the top-level CUDA_VISIBLE_DEVICES variable set by Ray\n",
    "        # so that vLLM can manage its own device placement within the worker.\n",
    "        os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "llm = ray.remote(\n",
    "    num_cpus=0,\n",
    "    num_gpus=0,\n",
    "    scheduling_strategy=scheduling_inference,\n",
    ")(MyLLM).remote(\n",
    "    model=MODEL_NAME,\n",
    "    skip_tokenizer_init = False,\n",
    "    enable_prefix_caching = True,\n",
    "    swap_space = 1, \n",
    "    gpu_memory_utilization = 0.6, \n",
    "    max_model_len = 2048, \n",
    "    enable_sleep_mode = True, \n",
    "    dtype = torch.bfloat16,\n",
    "    enforce_eager=True,\n",
    "    worker_extension_cls=\"vllm_utils.WorkerExtension\",\n",
    "    tensor_parallel_size=2,\n",
    "    distributed_executor_backend=\"ray\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Prompt: 'Hello, my name is'\n",
      "Generated text: ' John and I am a 15 year old boy. I am a student'\n",
      "--------------------------------------------------\n",
      "Prompt: 'The president of the United States is'\n",
      "Generated text: ' the head of state and head of government of the United States. The president directs'\n",
      "--------------------------------------------------\n",
      "Prompt: 'The capital of France is'\n",
      "Generated text: ' Paris. The capital of the United States is Washington, D.C. The capital'\n",
      "--------------------------------------------------\n",
      "Prompt: 'The future of AI is'\n",
      "Generated text: ' in the hands of the people who create it. The people who build AI systems'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test that the llm works on sample genrations \n",
    "\n",
    "# Generate text from the prompts.\n",
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0)\n",
    "\n",
    "outputs = ray.get(llm.generate.remote(prompts, sampling_params))\n",
    "\n",
    "print(\"-\" * 50)\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}\\nGenerated text: {generated_text!r}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and yes it does! so the last step of this process is to establish the NCCL communicator process group that enables rpc'ing the weights from training policy to inference engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-04 01:12:47 [pynccl.py:111] vLLM is using nccl==2.27.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the communication channel between the training process and the\n",
    "# inference engine.\n",
    "master_address = get_ip()\n",
    "master_port = get_open_port()\n",
    "\n",
    "handle = llm.collective_rpc.remote(\n",
    "    \"init_weight_update_group\", args=(master_address, master_port, 1, 3)\n",
    ")\n",
    "\n",
    "model_update_group = stateless_init_process_group(\n",
    "    master_address, master_port, 0, 3, torch.device(\"cuda:0\")\n",
    ")\n",
    "ray.get(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x7f0fd4cd7ca0>\n",
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.q_proj.bias\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.k_proj.bias\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.v_proj.bias\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.q_proj.bias\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.k_proj.bias\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.v_proj.bias\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.q_proj.bias\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.k_proj.bias\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.v_proj.bias\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.q_proj.bias\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.k_proj.bias\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.v_proj.bias\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.q_proj.bias\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.k_proj.bias\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.v_proj.bias\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.q_proj.bias\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.k_proj.bias\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.v_proj.bias\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.q_proj.bias\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.k_proj.bias\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.v_proj.bias\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.q_proj.bias\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.k_proj.bias\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.v_proj.bias\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.q_proj.bias\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.k_proj.bias\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.v_proj.bias\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.q_proj.bias\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.k_proj.bias\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.v_proj.bias\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.q_proj.bias\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.k_proj.bias\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.v_proj.bias\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.q_proj.bias\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.k_proj.bias\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.v_proj.bias\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.q_proj.bias\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.k_proj.bias\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.v_proj.bias\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.q_proj.bias\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.k_proj.bias\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.v_proj.bias\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.q_proj.bias\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.k_proj.bias\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.v_proj.bias\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.q_proj.bias\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.k_proj.bias\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.v_proj.bias\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.q_proj.bias\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.k_proj.bias\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.v_proj.bias\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.q_proj.bias\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.k_proj.bias\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.v_proj.bias\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.q_proj.bias\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.k_proj.bias\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.v_proj.bias\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.q_proj.bias\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.k_proj.bias\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.v_proj.bias\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.q_proj.bias\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.k_proj.bias\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.v_proj.bias\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.q_proj.bias\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.k_proj.bias\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.v_proj.bias\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.q_proj.bias\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.k_proj.bias\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.v_proj.bias\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.q_proj.bias\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.k_proj.bias\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.v_proj.bias\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.q_proj.bias\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.k_proj.bias\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.v_proj.bias\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.q_proj.bias\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.k_proj.bias\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.v_proj.bias\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.q_proj.bias\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.k_proj.bias\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.v_proj.bias\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.q_proj.bias\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.k_proj.bias\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.v_proj.bias\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.q_proj.bias\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.k_proj.bias\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.v_proj.bias\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.q_proj.bias\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.k_proj.bias\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.v_proj.bias\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.q_proj.bias\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.k_proj.bias\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.v_proj.bias\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.q_proj.bias\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.k_proj.bias\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.v_proj.bias\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "model.layers.32.self_attn.q_proj.weight\n",
      "model.layers.32.self_attn.q_proj.bias\n",
      "model.layers.32.self_attn.k_proj.weight\n",
      "model.layers.32.self_attn.k_proj.bias\n",
      "model.layers.32.self_attn.v_proj.weight\n",
      "model.layers.32.self_attn.v_proj.bias\n",
      "model.layers.32.self_attn.o_proj.weight\n",
      "model.layers.32.mlp.gate_proj.weight\n",
      "model.layers.32.mlp.up_proj.weight\n",
      "model.layers.32.mlp.down_proj.weight\n",
      "model.layers.32.input_layernorm.weight\n",
      "model.layers.32.post_attention_layernorm.weight\n",
      "model.layers.33.self_attn.q_proj.weight\n",
      "model.layers.33.self_attn.q_proj.bias\n",
      "model.layers.33.self_attn.k_proj.weight\n",
      "model.layers.33.self_attn.k_proj.bias\n",
      "model.layers.33.self_attn.v_proj.weight\n",
      "model.layers.33.self_attn.v_proj.bias\n",
      "model.layers.33.self_attn.o_proj.weight\n",
      "model.layers.33.mlp.gate_proj.weight\n",
      "model.layers.33.mlp.up_proj.weight\n",
      "model.layers.33.mlp.down_proj.weight\n",
      "model.layers.33.input_layernorm.weight\n",
      "model.layers.33.post_attention_layernorm.weight\n",
      "model.layers.34.self_attn.q_proj.weight\n",
      "model.layers.34.self_attn.q_proj.bias\n",
      "model.layers.34.self_attn.k_proj.weight\n",
      "model.layers.34.self_attn.k_proj.bias\n",
      "model.layers.34.self_attn.v_proj.weight\n",
      "model.layers.34.self_attn.v_proj.bias\n",
      "model.layers.34.self_attn.o_proj.weight\n",
      "model.layers.34.mlp.gate_proj.weight\n",
      "model.layers.34.mlp.up_proj.weight\n",
      "model.layers.34.mlp.down_proj.weight\n",
      "model.layers.34.input_layernorm.weight\n",
      "model.layers.34.post_attention_layernorm.weight\n",
      "model.layers.35.self_attn.q_proj.weight\n",
      "model.layers.35.self_attn.q_proj.bias\n",
      "model.layers.35.self_attn.k_proj.weight\n",
      "model.layers.35.self_attn.k_proj.bias\n",
      "model.layers.35.self_attn.v_proj.weight\n",
      "model.layers.35.self_attn.v_proj.bias\n",
      "model.layers.35.self_attn.o_proj.weight\n",
      "model.layers.35.mlp.gate_proj.weight\n",
      "model.layers.35.mlp.up_proj.weight\n",
      "model.layers.35.mlp.down_proj.weight\n",
      "model.layers.35.input_layernorm.weight\n",
      "model.layers.35.post_attention_layernorm.weight\n",
      "model.norm.weight\n"
     ]
    }
   ],
   "source": [
    "# do a test swap \n",
    "print(policy_model.named_parameters())\n",
    "\n",
    "# Synchronize the updated weights to the inference engine.\n",
    "for name, p in policy_model.named_parameters():\n",
    "    dtype_name = str(p.dtype).split(\".\")[-1]\n",
    "    if \"module\" in name: \n",
    "        name = name.replace(\"module.\", \"\")\n",
    "    print(name)\n",
    "    handle = llm.collective_rpc.remote(\n",
    "        \"update_weight\", args=(name, dtype_name, p.shape)\n",
    "    )\n",
    "    model_update_group.broadcast(p, src=0, stream=torch.cuda.current_stream())\n",
    "    ray.get(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did we actually see the weights get updated? \n",
    "\n",
    "all(ray.get(llm.collective_rpc.remote(\"check_weights_changed\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the RL loop, we need to set up all necessary components:\n",
    "\n",
    "- **Policy Model**: The main model that will be trained using policy gradients.\n",
    "- **Reference Model**: A frozen copy of the base model used for KL regularization.\n",
    "- **DeepSpeed**: Both models are initialized with DeepSpeed.\n",
    "- **vLLM Inference Engine**: Used for fast, batched inference during episode generation.\n",
    "- **WandB Logging**: We initialize WandB to track training metrics, hyperparameters, and checkpoints.\n",
    "\n",
    "Finally, if an existing checkpoint is detected, we automatically resume training from where it left off. \n",
    "\n",
    "Couple of remarks:\n",
    "- We move the reference to CPU and only take back to GPU during policy gradient computation. Because of the relatievely small size of the model, this moving back and forth from GPU to CPU is super fast.\n",
    "- Despite the entire training being run on a single GPU, we still use DeepSeed Zero stage 2. This is because the stage 2 comes with some optimization that avoid memory fragmentations, allowing to fully utilize GPU memory.\n",
    "- Flash Attention is required in our setup as it reduces the memory requirement of transformers from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$ where $n$ the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkranganathan\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kailash/nano-aha-moment/wandb/run-20251204_011353-v2wl0rqu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kranganathan/r1-single-gpu/runs/v2wl0rqu' target=\"_blank\">r1-zero</a></strong> to <a href='https://wandb.ai/kranganathan/r1-single-gpu' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kranganathan/r1-single-gpu' target=\"_blank\">https://wandb.ai/kranganathan/r1-single-gpu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kranganathan/r1-single-gpu/runs/v2wl0rqu' target=\"_blank\">https://wandb.ai/kranganathan/r1-single-gpu/runs/v2wl0rqu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Initialize main and reference models\n",
    "# policy_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=0,\n",
    "# )\n",
    "# reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=0,\n",
    "# )\n",
    "# policy_model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "\n",
    "\n",
    "# # Initialize DeepSpeed engines\n",
    "# policy_model, *_ = deepspeed.initialize(\n",
    "#     model=policy_model,\n",
    "#     config=deepspeed_config,\n",
    "#     model_parameters=policy_model.parameters(),\n",
    "# )\n",
    "# reference_model, *_ = deepspeed.initialize(\n",
    "#     model=reference_model,\n",
    "#     config=ref_deepspeed_config,\n",
    "# )\n",
    "\n",
    "# reference_model.module.cpu()\n",
    "\n",
    "# ############################################\n",
    "# # Initialize vLLM (Inference) engine\n",
    "# ############################################\n",
    "\n",
    "# inference_engine = LLM(\n",
    "#     model=MODEL_NAME,\n",
    "#     skip_tokenizer_init=False,\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     enable_prefix_caching=True,\n",
    "#     swap_space=1,\n",
    "#     scheduling_policy=\"fcfs\",\n",
    "#     dtype=torch.bfloat16,\n",
    "#     max_model_len=2048,\n",
    "#     enable_sleep_mode=True,\n",
    "#     worker_extension_cls=\"vllm_utils.WorkerExtension\"\n",
    "# )\n",
    "\n",
    "# Wandb for logging\n",
    "wandb.init(\n",
    "    project=\"r1-single-gpu\",\n",
    "    name=RUN_NAME,\n",
    "    config={\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"num_iterations\": NUM_ITERATIONS,\n",
    "        \"episodes_per_iteration\": EPISODES_PER_ITERATION,\n",
    "        \"rollouts_per_episode\": GENERATIONS_PER_SAMPLE,\n",
    "        \"kl_coefficient\": KL_COEFFICIENT,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "begin_iter = 0\n",
    "ckpt_path, ckpt_iter = find_last_checkpoint(EXP_DIR)\n",
    "if ckpt_path is not None:\n",
    "    print(f\"Resuming from checkpoint {ckpt_path} at iteration {ckpt_iter}\")\n",
    "    out = policy_model.load_checkpoint(ckpt_path / \"deepspeed\")\n",
    "    if out is None:\n",
    "        raise RuntimeError(f\"Failed to load checkpoint {ckpt_path}\")\n",
    "    begin_iter = ckpt_iter + 1\n",
    "    load_model_into_vllm(policy_model, model_update_group, inference_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_engine = llm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up, we are ready to start the main training loop. Each iteration of the loop performs the following steps:\n",
    "\n",
    "1. **Evaluation** (optional): \n",
    "Every few iterations, the model is evaluated on a test set to monitor progress.\n",
    "2. **Episode Generation**\n",
    "A batch of prompts is sampled, and multiple responses are generated for each prompt using the inference engine. Then we put the inference engine to sleep.\n",
    "3. **Reward Computation**\n",
    "Rewards and advantages for each generated episode are computed.\n",
    "4. **Policy Gradient Training**\n",
    "Using the computed advantages, we calculate the policy gradient loss and update the model parameters. The training is done using gradient accumulation to handle large batches. Note that we apply single gradient update per iteration.\n",
    "5. **Inference Engine Update**\n",
    "The inference engine is woken up and updated with the latest model weights.\n",
    "6. **Logging**\n",
    "Training and evaluation metrics are logged using WandB.\n",
    "7. **Checkpointing**\n",
    "Every 50 iterations, the model and optimizer states are saved.\n",
    "\n",
    "This loop continues until the specified number of iterations is completed.\n",
    "\n",
    "**Sleeping of vLLM**\n",
    "Before training begins, we put vLLM into sleep mode to free up its KV cache and model weights, ensuring enough GPU memory is available for policy training. After the training step is complete, vLLM is woken up, reinitializing its KV cache and preparing for the next round of sampling using the updated model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/1000\n",
      "Evaluating on eval set...\n",
      "Generated 64 responses\n",
      "########## Example 1 (Reward: 0.0, Response Length: 1024)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [26, 30, 24, 31], create an equation that equals 29. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "`First, let's list out all the possible combinations:</think>\n",
      "1. (26 / 30) + 24 - 31\n",
      "2. 26 / (30 - 24) - 31\n",
      "3. (26 - 30) * 24 + 31\n",
      "4. 26 * (30 / 24) - 31\n",
      "5. 26 / (30 - 24) * 31\n",
      "6. (26 / 30) * 24 + 31\n",
      "7. 26 / ((30 - 24) * 31)\n",
      "8. 26 - (30 * 24) / 31\n",
      "9. 26 - (30 / 24) / 31\n",
      "10. (26 + 24) / 30 - 31\n",
      "11. (26 - 30) + 24 / 31\n",
      "12. 26 + (30 * 24) / 31\n",
      "13. 26 - (30 / 24) + 31\n",
      "14. (26 * 24) / 30 - 31\n",
      "15. 26 + (30 - 24) / 31\n",
      "16. 26 + (31 * 24) / 30\n",
      "17. 26 + (30 * 24) / 31\n",
      "18. 26 - (30 / 24) - 31\n",
      "19. 26 + (30 / 24) + 31\n",
      "20. 26 + (30 / 24 * 31)\n",
      "21. 26 - (30 / 24 + 31)\n",
      "22. (26 / 30) + (24 * 31)\n",
      "23. (26 / 30) * (24 + 31)\n",
      "\n",
      "For simplicity, I will choose option 4 and option 11:\n",
      "(think)Final equation for 4:\n",
      "<answer>(26 * 24) / 30 - 31</answer>\n",
      "(think)Final equation for 11:\n",
      "<answer>(26 - (30 / 24) - 31)</answer>\n",
      "<think>Checking the answers:\n",
      "(think)For 4:\n",
      "18 * 24 / 30 = 48 * 0.8 = 38.4 - 31 = 7.4\n",
      "(think)For 11:\n",
      "26 - (30 / 24) - 31 = false\n",
      "<think>I see that I made an mistake on the third one, exra c not making it answer ké. Let rerun the final onesound..urrenc\")\n",
      "<answer>(26 / 30) + (24 * 31) = (26 / 30) + 744 = false\n",
      "(think)For 20:\n",
      "<answer>26 + (30 / 24) + 31 = 26 + 300 / 24 + 31</answer>\n",
      "</think>\n",
      "<ul>\n",
      "<li>26 + (30 / 24) + 31 = false</li>\n",
      "<li>(30 * 24) / 31 - 30 = false</li>\n",
      "<li>(30 - 24) + 26 / 31 = 16 + 26 / 31 = false</li>\n",
      "<li>((26 * 24) / 30 - 31) = 26</li>\n",
      "<li>(26 + 24) / 30 - 31 = 2</li>\n",
      "<li>26 / (30 - 24) - 31 = false</li>\n",
      "<li>(26 - 30) + 24 / 31 = false</li>\n",
      "<li>(26 + 24) / 30 - 31 = 2 = 2</li>\n",
      "<li>(26 - 30) * 24 + 31 = false</li>\n",
      "<li>26 * (30 / 24) - 31 = false</li>\n",
      "<li>(26 * 24) / 30 - 31 = 26</li>\n",
      "<li>(26 - 30) / 24 - 31 = false</li>\n",
      "<li>(26 +`\n",
      "\n",
      "\n",
      "########## Example 2 (Reward: 0.0, Response Length: 202)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [26, 30, 24, 31], create an equation that equals 29. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "` I need to use all four numbers (26, 30, 24, 31), and each number can be used only once. I can add, subtract, multiply, or divide the numbers. By manipulating these calculations, I can try to reach a target value of 29. </think>\n",
      "Deriving the final equation:\n",
      "<answer>(31 - 26) * (24 / 30)</answer>\n",
      "So, the equation is <answer>(31 - 26) * (24 / 30)</answer>, and the answer is 29.\n",
      " students\n",
      "的学生\n",
      "繧raquo strong\n",
      "\n",
      "eso\n",
      "st Precalculus. Please send all relevant\n",
      "\n",
      "unchecked\n",
      "solution\n",
      "utes,\n",
      "sugar\n",
      "students\n",
      "soft\n",
      "ce\n",
      "student\n",
      "all\n",
      "et.-\n",
      "\n",
      "ite\n",
      "properly\n",
      "question\n",
      "():\n",
      "A\n",
      "PR=P\n",
      "end?:\n",
      "Step-by-step explanation:\n",
      "\n",
      " bànd\n",
      "avez\n",
      "tion\n",
      "x\n",
      "e<|endoftext|>`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation: 100%|██████████| 16/16 [00:20<00:00,  1.30s/it]\n",
      "  0%|          | 1/1000 [01:29<24:52:03, 89.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY METRICS: {'train/kl_penalty': np.float64(1.791613552605008e-05), 'train/rewards': np.float64(0.0703125), 'train/reward_metrics/format_reward': np.float64(0.0703125), 'train/reward_metrics/equation_reward': np.float64(0.0), 'eval/rewards': np.float64(0.284), 'eval/reward_metrics/format_reward': np.float64(0.27), 'eval/reward_metrics/equation_reward': np.float64(0.014)}\n",
      "Iteration 1/1000\n",
      "Generated 64 responses\n",
      "########## Example 1 (Reward: 0.0, Response Length: 1024)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [40, 49, 24], create an equation that equals 33. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "`1. Identify the main target number that the equation should equal to: 33\n",
      "2. Choose the two larger numbers: 49 and 24, because they contribute most to the sum required\n",
      "3. Calculate their difference with the larger number: 49 - 24 = 25\n",
      "4. Subtract 25 from 33: 33 - 25 = 8\n",
      "5. Now, find the remaining number: 8 is too small to be the result of any operation with the background number 49, which exceeds 10. Therefore, we need to make some adjustments.\n",
      "6. Divide 49 by 25: 49 / 25 = 1.96\n",
      "7. Now, multiply 40 by 1.96: 40 * 1.96 = 78.4 (which is not equal to 33)\n",
      "8. Subtract 78.4 from 78 to make it closer to 33: 78 - 78.4 = -0.4 (not needed yet)\n",
      "9. Continue dividing 49 by remaining 1 (from initial division): 49 / 1 = 49\n",
      "10. Add 49 to 0.4: 49 + 0.4 = 49.4 (not equal to 33)\n",
      "11. Add another 1 (from previous division): 49.4 + 1 = 50.4 (not equal to 33)\n",
      "12. Continue adding 1 until 50.4 becomes 33.\n",
      "13. Add 1 until 40 becomes 33: 40 + 1 = 41, 41 + 1 = 42, 42 + 1 = 43, 43 + 1 = 44, 44 + 1 = 45, 45 + 1 = 46, 46 + 1 = 47, 47 + 1 = 48, 48 + 1 = 49, 49 - 6 = 33 }</think>\n",
      "❼<answer> 40 + 6 = 44</answer>\n",
      "❼<answer>44 - 1 = 43</answer>\n",
      "❼<answer>43 - 1 = 42</answer>\n",
      "❼<answer>42 - 2 = 40</answer>\n",
      "❼<answer>40 + 8 = 48</answer>\n",
      "❼<answer>48 - 7 = 41</answer>\n",
      "❼<answer>41 - 6 = 35</answer>\n",
      "❼<answer>35 + 6 = 41</answer>\n",
      "❼<answer>41 - 3 = 38</answer>\n",
      "❼<answer>38 + 4 = 42</answer>\n",
      "❼<answer>42 - 3 = 39</answer>\n",
      "❼<answer>39 + 4 = 43</answer>\n",
      "❼<answer>43 - 1 = 42</answer>\n",
      "❼<answer>42 + 8 = 50</answer>\n",
      "❼<answer>50 - 7 = 43</answer>\n",
      "⼃  <answer>43 - 2 = 41</answer>\n",
      "⼃  <answer>41 - 8 = 33</answer>\n",
      "⼃  <answer numeric>43</answer>\n",
      "⼃  <answer>43 - 9 = 34</answer>\n",
      "⼃  <answer>34 + 2 = 36</answer>\n",
      "⼃  <answer>36 - 3 = 33</answer>\n",
      "⼃  <answer>33 + 2 = 35</answer>\n",
      "⼃  <answer>35 - 4 = 31</answer>\n",
      "⼃  <answer>31 + 4 = 35</answer>\n",
      "⼃  <answer>35 - 8 = 27</answer>\n",
      "⼃  <answer>27 + 2 = 29</answer>\n",
      "⼃  <answer>29 - 3 = 26</answer>\n",
      "⼃  <answer>26 + 4 = 30</answer>\n",
      "⼃  <answer>30 - 1 = 29</answer>\n",
      "⼃  <answer>29 + 5 = 34</answer>\n",
      "⼃  <answer numeric>34</answer`\n",
      "\n",
      "\n",
      "########## Example 2 (Reward: 0.0, Response Length: 503)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [40, 49, 24], create an equation that equals 33. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "` The problem is to create an equation that equals 33 using the numbers 40, 49, and 24. We can use basic arithmetic operations and each number can only be used once. \n",
      "\n",
      "We can start by subtracting the smallest number from the largest and rearranging the others. We can try (49 - 24) - 40. This gives us -11, which is not equal to 33. \n",
      "\n",
      "Let me try a different approach. We can try (40 + 49) - 24. This gives us 75 - 24, which equals 51, not 33. \n",
      "\n",
      "I'll try another approach. Let's try (40 * 49) / 24. This gives us 1960 / 24, which is not an integer. \n",
      "\n",
      "Finally, let me try a different combination. Let's try (49 * 24) - 40. This gives us 1176 - 40, which equals 1136, not 33. \n",
      "\n",
      "I think I have found the solution. Let me try (49 / 40) * 24. This gives us 24.05, which is not an integer. \n",
      "\n",
      "Let me try one more combination. Let's try 49 / (40 - 24). This gives us 2.5, which is not an integer. \n",
      "\n",
      "I think I am out of ideas. Let me review my attempts. \n",
      "\n",
      "49 - (40 / 24) ≈ 40.43\n",
      "\n",
      "40 / (49 - 24) ≈ 1.52\n",
      "\n",
      "49 * (24 / 40) = 27.99\n",
      "\n",
      "(40 * 24) / 49 ≈ 20.23\n",
      "\n",
      "(24 / 49) * 40 ≈ 17.64\n",
      "\n",
      "49 / (40 - 24) ≈ 25.29\n",
      "\n",
      "None of these combinations are going to give me an integer result. I am out of ideas and running out of time. Let me guess. \n",
      "\n",
      "<answer>(49 - 24) / 40</answer>\n",
      "ification完成后resolver\n",
      "7.50<|endoftext|>`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation: 100%|██████████| 16/16 [00:20<00:00,  1.29s/it]\n",
      "  0%|          | 2/1000 [02:23<18:56:28, 68.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY METRICS: {'train/kl_penalty': np.float64(1.996347813509474e-05), 'train/rewards': np.float64(0.1015625), 'train/reward_metrics/format_reward': np.float64(0.1015625), 'train/reward_metrics/equation_reward': np.float64(0.0)}\n",
      "Iteration 2/1000\n",
      "Generated 64 responses\n",
      "########## Example 1 (Reward: 0.0, Response Length: 163)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [9, 4, 99], create an equation that equals 27. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "`Calculate how many times I can use number 9 without exceeding 27. It seems I can only use it once, so I'll calculate (9 * 3). Now I need to get to 27 from this figure, but any side effects of - (because after 3 times 9, 27 would be 27 times 3, or 81). So, let's use -4 instead of 4 for the last level. Therefore, the equation is (9 * 3) - 4 = 27.</think>\n",
      "<answer>(9 * 3) - 4 = 27</answer>\n",
      " Solve this mathematical expression.\n",
      ">>();\n",
      "cery\n",
      "``\n",
      "={({‍ключ:)‍. Hello my Name is and me is ת userInput.Email<|endoftext|>`\n",
      "\n",
      "\n",
      "########## Example 2 (Reward: 0.0, Response Length: 121)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [9, 4, 99], create an equation that equals 27. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "`Given the numbers [9, 4, 99], we need to create an equation that equals 27. We can use basic arithmetic operations of addition (+), subtraction (-), multiplication (*) and division (/) to solve this problem. Each number can be used only once. <think>I'll check all the possible combinations and operations to see which one results in the answer 27.</think> </think>\n",
      "<answer>(9 + 4) * 3</answer>\n",
      "So, the equation is (9 + 4) * 3, which equals 27.<|endoftext|>`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation: 100%|██████████| 16/16 [00:20<00:00,  1.29s/it]\n",
      "  0%|          | 3/1000 [03:19<17:24:43, 62.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY METRICS: {'train/kl_penalty': np.float64(2.4650141285618763e-05), 'train/rewards': np.float64(0.0625), 'train/reward_metrics/format_reward': np.float64(0.0625), 'train/reward_metrics/equation_reward': np.float64(0.0)}\n",
      "Iteration 3/1000\n",
      "Generated 64 responses\n",
      "########## Example 1 (Reward: 0.0, Response Length: 994)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [66, 45, 34], create an equation that equals 77. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "`Starting with 66, I can subtract 34, which leaves [32].\n",
      "Now, I can add 45, which gives me [77]. So the equation seems like [66 - 34 + 45 = 77]</think>\n",
      "\n",
      "However, since you mentioned each number can only be used once, let's try another approach.\n",
      "<think>First, I need to subtract one of the numbers from 66. Let's subtract 45, which leaves me with 21.\n",
      "Now, I can add 34 to this, giving me [21 + 34 = 55].\n",
      "To reach 77 using only three numbers, I will need to add numbers in a different way.</think>\n",
      "\n",
      "If we try multiplying 66 by 1.2, we'll get 79.2, a number close to 77. Since 66 is divisible by 3, we can divide 66 by 3, which gives us 22. Adding 25 (which comes from 66 minus 41 since 41 is the value of 34 divided by 77) will give us [66 / 3 + 22 = 34 + 22 = 56 + 21 = 77]</think>\n",
      "\n",
      "However, this solution doesn't follow your initial condition about using <number>, <number>, <number>. Let's try another solution.\n",
      "<think>Since 66 is divisible by 6, and 45 is divisible by 15, we can divide 66 by 6, which gives us 11. Adding 26 (which comes from 66 - 40 since 40 is the value of 34 divided by 26.9 or 66 divided by 2.6 or 66 divided by 34/7.3, if you prefer approximations), will give us [66 / 6 + 26 = 11 + 26 = 37 + 26 = 83 - 76 = 77]</think>\n",
      "\n",
      "This solution doesn't work either since I can't reach 77 just with the added number.\n",
      "<answer>(66 / 6 + 45 * 1) + 34 = 77</answer>\n",
      "<!--\n",
      "(66 / 6 + 45 * 1) + 34 = 77\n",
      "-->\n",
      "<!--\n",
      "Next, we have: for [66],[45],[34], we find: [66 / 6 + 45 * 1] + 34 = 77. This indeed makes the calculation indicated.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are allowed to override the MSC/Safety System limits (standard, head, shoulder)\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are expected to experiment more when you are free from time constraints.\n",
      "-->\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "-->\n",
      "\n",
      "<!--\n",
      "You are encouraged to always begin from scratch when you are free from time constraints.\n",
      "--><|endoftext|>`\n",
      "\n",
      "\n",
      "########## Example 2 (Reward: 0.5, Response Length: 105)\n",
      "#### Query:\n",
      "`<|im_start|>system\n",
      "You are a helpful assistant. You first think about the reasoning process in the mind and then provide the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Using the numbers [66, 45, 34], create an equation that equals 77. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer>(1 + 2) / (3 * 5)</answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>`\n",
      "#### Response:\n",
      "` You can see that to make the equation equal to 77, the number 77 must be the result of the arithmetic operations. The numbers given are [66, 45, 34]. Adding these numbers would exceed 77. It seems that we can use the subtraction operation. Combine 45 with 34 first and subtract the result from 66.</think>\n",
      "<answer>(66 - (45 + 34)) = 77</answer><|endoftext|>`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation: 100%|██████████| 16/16 [00:20<00:00,  1.30s/it]\n",
      "  0%|          | 4/1000 [04:15<16:40:16, 60.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY METRICS: {'train/kl_penalty': np.float64(2.1759995018610674e-05), 'train/rewards': np.float64(0.09375), 'train/reward_metrics/format_reward': np.float64(0.09375), 'train/reward_metrics/equation_reward': np.float64(0.0)}\n",
      "Iteration 4/1000\n"
     ]
    }
   ],
   "source": [
    "for iteration in trange(NUM_ITERATIONS):\n",
    "    print(f\"Iteration {iteration}/{NUM_ITERATIONS}\")\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    #########################################################\n",
    "    # Evaluation\n",
    "    #########################################################\n",
    "\n",
    "    eval_stats = None\n",
    "    if iteration % 25 == 0:\n",
    "        print(\"Evaluating on eval set...\")\n",
    "        eval_episodes, eval_stats = utils.evaluate_on_test_set(\n",
    "            inference_engine=inference_engine,\n",
    "            test_dataset=test_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            eos_token=EOS_TOKEN,\n",
    "            eval_sampling_params=SamplingParams(\n",
    "                temperature=0.3,\n",
    "                max_tokens=1024,\n",
    "                n=1,\n",
    "                detokenize=False,\n",
    "                stop_token_ids=[EOS_TOKEN_ID],\n",
    "            ),\n",
    "            reward_func=lambda completion, sample: compute_reward(\n",
    "                completion, sample\n",
    "            ),\n",
    "        )\n",
    "        eval_episode_table = dump_episodes(\n",
    "            episodes=eval_episodes,\n",
    "            episodes_stats=eval_stats,\n",
    "            exp_dir=EXP_DIR,\n",
    "            tokenizer=tokenizer,\n",
    "            iteration=iteration,\n",
    "            is_eval=True,\n",
    "        )\n",
    "        wandb.log({\"eval/episodes\": eval_episode_table, \"iteration\": iteration})\n",
    "\n",
    "\n",
    "    #########################################################\n",
    "    # Generate Episodes\n",
    "    #########################################################\n",
    "\n",
    "    # Sample training batch\n",
    "    num_samples = EPISODES_PER_ITERATION // GENERATIONS_PER_SAMPLE\n",
    "    indices = np.random.choice(\n",
    "        len(train_dataset), size=num_samples, replace=False\n",
    "    )\n",
    "    samples = train_dataset.select(indices)\n",
    "\n",
    "    requests = [TokensPrompt(prompt_token_ids = r) for r in list(samples[\"input_ids\"])]\n",
    "\n",
    "    # Sample responses\n",
    "    outputs = ray.get(inference_engine.generate.remote(\n",
    "        requests,\n",
    "        sampling_params=SamplingParams(\n",
    "            n=GENERATIONS_PER_SAMPLE,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P,\n",
    "            top_k=TOP_K,\n",
    "            max_tokens=MAX_RESPONSE_TOKENS,\n",
    "            detokenize=False,\n",
    "            stop_token_ids=[EOS_TOKEN_ID],\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    all_generations = [list(g.token_ids) for out in outputs for g in out.outputs]\n",
    "    all_finish_reasons = [g.finish_reason for out in outputs for g in out.outputs]\n",
    "\n",
    "    # if the inference engine lies on a different machine, then we don't actually need to sleep and remove all vllm state/cache\n",
    "    # inference_engine.sleep(1)\n",
    "\n",
    "    print(f\"Generated {len(all_generations)} responses\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Process responses and calculate rewards\n",
    "    episodes, episodes_stats = create_training_episodes(\n",
    "        samples,\n",
    "        all_generations,\n",
    "        all_finish_reasons,\n",
    "    )\n",
    "    for k, v in episodes_stats.items():\n",
    "        metrics.setdefault(k, []).extend(v)\n",
    "\n",
    "\n",
    "\n",
    "    episode_table = dump_episodes(\n",
    "        episodes=episodes,\n",
    "        episodes_stats=episodes_stats,\n",
    "        exp_dir=EXP_DIR,\n",
    "        tokenizer=tokenizer,\n",
    "        iteration=iteration,\n",
    "    )\n",
    "\n",
    "    #########################################################\n",
    "    # Training\n",
    "    #########################################################\n",
    "\n",
    "    # Prepare training batch\n",
    "    model_inputs = prepare_model_inputs(\n",
    "        query_token_ids=episodes[\"all_query_token_ids\"],\n",
    "        response_token_ids=episodes[\"all_response_token_ids\"],\n",
    "        advantages=episodes[\"all_advantages\"],\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    # Calculate losses and update model\n",
    "    policy_model.train()\n",
    "    reference_model.module.cuda()\n",
    "    reference_model.eval()\n",
    "\n",
    "    total_response_len = (model_inputs[\"labels\"] != -100).sum().item()\n",
    "\n",
    "    for i in trange(0, EPISODES_PER_ITERATION, PER_DEVICE_BATCH_SIZE, desc=\"Gradient Accumulation\"):\n",
    "        batch = {\n",
    "            k: v[i : i + PER_DEVICE_BATCH_SIZE]\n",
    "            for k, v in model_inputs.items()\n",
    "        }\n",
    "\n",
    "        # Compute policy gradient loss\n",
    "        loss, loss_metrics = compute_pg_loss(\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            batch=batch,\n",
    "            total_response_len=total_response_len,\n",
    "        )\n",
    "\n",
    "        # Track metrics\n",
    "        metrics.setdefault(\"loss\", []).append(loss.item())\n",
    "        grad_norm = policy_model.get_global_grad_norm()\n",
    "        if grad_norm is not None:\n",
    "            grad_norm = grad_norm.item()\n",
    "        metrics.setdefault(\"grad_norm\", []).append(grad_norm)\n",
    "        for k, v in loss_metrics.items():\n",
    "            metrics.setdefault(k, []).append(v.item() if isinstance(v, torch.Tensor) else v)\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        policy_model.backward(loss, scale_wrt_gas=False)\n",
    "        \n",
    "        # Free memory\n",
    "        del loss, loss_metrics\n",
    "        if policy_model.is_gradient_accumulation_boundary():\n",
    "            reference_model.module.cpu()\n",
    "\n",
    "        policy_model.step()\n",
    "\n",
    "    #########################################################\n",
    "    # Update inference engine weights\n",
    "    #########################################################\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "    #inference_engine.wake_up()\n",
    "    load_model_into_vllm(policy_model, model_update_group, inference_engine)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    #########################################################\n",
    "    # Log metrics\n",
    "    #########################################################\n",
    "\n",
    "    train_metrics = {\n",
    "        k: np.mean(v) for k, v in metrics.items() if None not in v\n",
    "    }\n",
    "    train_metrics[\"learning_rate\"] = policy_model.get_lr()[0]\n",
    "    logs = {\n",
    "        \"iteration\": iteration,\n",
    "        f\"episodes/iter_{iteration:06d}\": episode_table,\n",
    "        **{f\"train/{k}\": v for k, v in train_metrics.items()},\n",
    "    }\n",
    "    if eval_stats is not None:\n",
    "        eval_metrics = {k: np.mean(v) for k, v in eval_stats.items() if None not in v}\n",
    "        logs.update({f\"eval/{k}\": v for k, v in eval_metrics.items()})\n",
    "    wandb.log(logs)\n",
    "\n",
    "    selected_keys = [\n",
    "        \"train/kl_penalty\",\n",
    "        \"train/rewards\",\n",
    "        \"train/reward_metrics/format_reward\",\n",
    "        \"train/reward_metrics/equation_reward\",\n",
    "        \"eval/rewards\",\n",
    "        \"eval/reward_metrics/format_reward\",\n",
    "        \"eval/reward_metrics/equation_reward\",\n",
    "    ]\n",
    "    selected_metrics = {k: logs[k] for k in selected_keys if k in logs}\n",
    "    print(f\"KEY METRICS: {selected_metrics}\")\n",
    "\n",
    "    if iteration % 50 == 0 and iteration != 0:\n",
    "        policy_model.module.save_pretrained(\n",
    "            str(EXP_DIR / \"checkpoints\" / f\"ckpt_{iteration:06d}\" / \"hf_model\")\n",
    "        )\n",
    "        policy_model.save_checkpoint(\n",
    "            str(EXP_DIR / \"checkpoints\" / f\"ckpt_{iteration:06d}\" / \"deepspeed\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.inputs import TokensPrompt \n",
    "\n",
    "requests = [TokensPrompt(prompt_token_ids = r) for r in list(test_dataset[\"input_ids\"])]\n",
    "\n",
    "inference_engine.generate(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this codebase in your research, please cite us using:\n",
    "\n",
    "```bibtex\n",
    "@misc{Kazemnejad2025:NanoAhaMoment,\n",
    "  author       = {Amirhossein Kazemnejad and Milad Aghajohari and Alessandro Sordoni and Aaron Courville and Siva Reddy},\n",
    "  title        = {Nano Aha! Moment: Lunch Break Reproduction of DeepSeek R1-Zero from Scratch},\n",
    "  year         = {2025},\n",
    "  howpublished = {\\url{https://github.com/McGill-NLP/nano-aha-moment}},\n",
    "  note         = {GitHub repository}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
